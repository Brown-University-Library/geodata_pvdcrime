{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, pandas as pd, geopandas as gpd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False while testing code, should be True for updates\n",
    "overwrite_files = True\n",
    "\n",
    "# Set to True to geocode all locations (including those that have already been geocoded) from scratch\n",
    "# Only used to ensure consistency of coordinate sources if geocoding method changes\n",
    "geocode_all = False # Should stay False for efficiency\n",
    "\n",
    "# Set to False to re-attempt geocoding for previously unmatched locations from the last 180 days\n",
    "exclude_past_no_match = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recent data (last 180 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-00103187</td>\n",
       "      <td>0 Block PARKIS AVE</td>\n",
       "      <td>2025-12-31T02:29:33.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/O $1500 - ALL OTH LARCENY</td>\n",
       "      <td>1</td>\n",
       "      <td>THoulihan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-00103182</td>\n",
       "      <td>0 Block EATON ST</td>\n",
       "      <td>2025-12-31T01:28:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Disorderly Conduct</td>\n",
       "      <td>11-45-1</td>\n",
       "      <td>DISORDERLY CONDUCT</td>\n",
       "      <td>1</td>\n",
       "      <td>BAucoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00103173</td>\n",
       "      <td>DEAN ST / SPRUCE ST</td>\n",
       "      <td>2025-12-30T23:53:23.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-00103163</td>\n",
       "      <td>0 Block DEPASQUALE AVE</td>\n",
       "      <td>2025-12-30T22:27:39.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-00103163</td>\n",
       "      <td>0 Block DEPASQUALE AVE</td>\n",
       "      <td>2025-12-30T22:27:39.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      casenumber                location            reported_date month  year  \\\n",
       "0  2025-00103187      0 Block PARKIS AVE  2025-12-31T02:29:33.000    12  2025   \n",
       "1  2025-00103182        0 Block EATON ST  2025-12-31T01:28:00.000    12  2025   \n",
       "2  2025-00103173     DEAN ST / SPRUCE ST  2025-12-30T23:53:23.000    12  2025   \n",
       "3  2025-00103163  0 Block DEPASQUALE AVE  2025-12-30T22:27:39.000    12  2025   \n",
       "4  2025-00103163  0 Block DEPASQUALE AVE  2025-12-30T22:27:39.000    12  2025   \n",
       "\n",
       "                 offense_desc statute_code  \\\n",
       "0              Larceny, Other      11-41-1   \n",
       "1          Disorderly Conduct      11-45-1   \n",
       "2  Larceny from Motor Vehicle      11-41-1   \n",
       "3  Larceny from Motor Vehicle      11-41-1   \n",
       "4                   Vandalism      11-44-1   \n",
       "\n",
       "                             statute_desc counts reporting_officer  \n",
       "0       LARCENY/O $1500 - ALL OTH LARCENY      1         THoulihan  \n",
       "1                      DISORDERLY CONDUCT      1           BAucoin  \n",
       "2               LARCENY/U $1500 - FROM MV      1           HViruet  \n",
       "3               LARCENY/U $1500 - FROM MV      1           HViruet  \n",
       "4  VANDALISM/MALICIOUS INJURY TO PROPERTY      1           HViruet  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that limit defaults to 1000\n",
    "data_url='https://data.providenceri.gov/resource/rz3y-pz8v.json?%24limit=20000'\n",
    "response=requests.get(data_url)\n",
    "results = response.json()\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df['year'] = results_df['year'].astype(int)\n",
    "years = results_df['year'].unique()\n",
    "\n",
    "print(len(results_df), \"rows\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully geocoded records\n",
    "past_df = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_geocoded.csv'))\n",
    "past_df['year'] = past_df['year'].astype(int)\n",
    "\n",
    "# Records that could not be geocoded\n",
    "past_no_matches = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_non_geocoded.csv'))\n",
    "past_no_matches['year'] = past_no_matches['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00103173</td>\n",
       "      <td>DEAN ST / SPRUCE ST</td>\n",
       "      <td>2025-12-30T23:53:23.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-00103047</td>\n",
       "      <td>SHILOH ST</td>\n",
       "      <td>2025-12-30T12:27:10.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ACommendatore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2025-00102891</td>\n",
       "      <td>100 Block RANDALL SQ</td>\n",
       "      <td>2025-12-29T18:12:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2025-00102864</td>\n",
       "      <td>FENNER ST</td>\n",
       "      <td>2025-12-29T15:51:03.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2025-00102704</td>\n",
       "      <td>600 BlockN MAIN ST</td>\n",
       "      <td>2025-12-28T17:43:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber              location            reported_date month  year  \\\n",
       "2   2025-00103173   DEAN ST / SPRUCE ST  2025-12-30T23:53:23.000    12  2025   \n",
       "18  2025-00103047             SHILOH ST  2025-12-30T12:27:10.000    12  2025   \n",
       "50  2025-00102891  100 Block RANDALL SQ  2025-12-29T18:12:00.000    12  2025   \n",
       "55  2025-00102864             FENNER ST  2025-12-29T15:51:03.000    12  2025   \n",
       "74  2025-00102704    600 BlockN MAIN ST  2025-12-28T17:43:00.000    12  2025   \n",
       "\n",
       "                  offense_desc statute_code  \\\n",
       "2   Larceny from Motor Vehicle      11-41-1   \n",
       "18                   Vandalism      11-44-1   \n",
       "50         Assault, Aggravated       11-5-2   \n",
       "55  Larceny from Motor Vehicle      11-41-1   \n",
       "74             Assault, Simple       11-5-3   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "2                   LARCENY/U $1500 - FROM MV      1           HViruet   \n",
       "18     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ACommendatore   \n",
       "50  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1         PHourahan   \n",
       "55                  LARCENY/U $1500 - FROM MV      1   Central Station   \n",
       "74                  SIMPLE ASSAULT OR BATTERY      1         PHourahan   \n",
       "\n",
       "   unique_id violent_cat property_cat  \n",
       "2        NaN         NaN          NaN  \n",
       "18       NaN         NaN          NaN  \n",
       "50       NaN         NaN          NaN  \n",
       "55       NaN         NaN          NaN  \n",
       "74       NaN         NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    # concatenate past_df, results_df, and past_no_matches\n",
    "    df_all = pd.concat((past_df, results_df, past_no_matches))\n",
    "    # drop dupilcate records\n",
    "    df_all = df_all.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    results_df = df_all\n",
    "else:\n",
    "    df2 = results_df.copy()\n",
    "    # Identify new records by case number and time\n",
    "    df1 = past_df[['casenumber', 'reported_date']]\n",
    "\n",
    "    if exclude_past_no_match:\n",
    "        # Exclude past locations which returned no location matches\n",
    "        df1 = pd.concat((df1, past_no_matches[['casenumber', 'reported_date']]))\n",
    "    else:\n",
    "        # Add previously unmatched locations to the df to attempt geocoding again\n",
    "        df2 = pd.concat((df2, past_no_matches[past_no_matches['year'].isin(years)]))\n",
    "        df2 = df2.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    merged = df2.merge(df1, on=['casenumber', 'reported_date'], how='left', indicator=True)\n",
    "\n",
    "    # Identify new case records\n",
    "    new_records = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    # results_df is the DataFrame which will be geocoded\n",
    "    results_df = new_records\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load E911 data\n",
    "(needed to geocode block locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:\n",
      "Index(['SiteType', 'Site_GUID', 'Add_Full', 'AddNumFull', 'AddNum_Pre',\n",
      "       'Add_Number', 'AddNum_Suf', 'St_Full', 'St_PreMod', 'St_PreDir',\n",
      "       'St_PreTyp', 'St_Name', 'St_PosType', 'St_PosDir', 'St_PosMod',\n",
      "       'MSAGComm', 'ESN', 'State', 'Post_Code', 'Country', 'St_Alias1',\n",
      "       'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments',\n",
      "       'DateUpdate', 'geometry', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Add_Full</th>\n",
       "      <th>Add_Number</th>\n",
       "      <th>St_Full</th>\n",
       "      <th>St_Name</th>\n",
       "      <th>St_Alias1</th>\n",
       "      <th>St_Alias2</th>\n",
       "      <th>St_Alias3</th>\n",
       "      <th>St_Alias4</th>\n",
       "      <th>St_Alias5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>121 FARMINGTON AV</td>\n",
       "      <td>121.0</td>\n",
       "      <td>farmington av</td>\n",
       "      <td>farmington</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2 stry lght blu wht trm frnt prch blk rail</td>\n",
       "      <td>41.805353</td>\n",
       "      <td>-71.459654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>2 DEERFIELD TERR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>brwn shngles 2stry wht trim</td>\n",
       "      <td>41.785448</td>\n",
       "      <td>-71.420708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>3 DEERFIELD TERR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2stry wht split blk shttrs frnt prch</td>\n",
       "      <td>41.785195</td>\n",
       "      <td>-71.420797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37275</th>\n",
       "      <td>98 CYR ST</td>\n",
       "      <td>98.0</td>\n",
       "      <td>cyr st</td>\n",
       "      <td>cyr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tan brck 1stry wht trim brwn shttrs R grg, see VC</td>\n",
       "      <td>41.785209</td>\n",
       "      <td>-71.404274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37308</th>\n",
       "      <td>179 WHEELER AV</td>\n",
       "      <td>179.0</td>\n",
       "      <td>wheeler av</td>\n",
       "      <td>wheeler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>grey 3stry red brck base red canopies frnt hedges</td>\n",
       "      <td>41.781818</td>\n",
       "      <td>-71.403718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Add_Full  Add_Number         St_Full     St_Name St_Alias1  \\\n",
       "30282  121 FARMINGTON AV       121.0   farmington av  farmington      None   \n",
       "37261   2 DEERFIELD TERR         2.0  deerfield terr   deerfield      None   \n",
       "37262   3 DEERFIELD TERR         3.0  deerfield terr   deerfield      None   \n",
       "37275          98 CYR ST        98.0          cyr st         cyr      None   \n",
       "37308     179 WHEELER AV       179.0      wheeler av     wheeler      None   \n",
       "\n",
       "      St_Alias2 St_Alias3 St_Alias4 St_Alias5  \\\n",
       "30282      None      None      None      None   \n",
       "37261      None      None      None      None   \n",
       "37262      None      None      None      None   \n",
       "37275      None      None      None      None   \n",
       "37308      None      None      None      None   \n",
       "\n",
       "                                                Comments   Latitude  Longitude  \n",
       "30282         2 stry lght blu wht trm frnt prch blk rail  41.805353 -71.459654  \n",
       "37261                        brwn shngles 2stry wht trim  41.785448 -71.420708  \n",
       "37262               2stry wht split blk shttrs frnt prch  41.785195 -71.420797  \n",
       "37275  tan brck 1stry wht trim brwn shttrs R grg, see VC  41.785209 -71.404274  \n",
       "37308  grey 3stry red brck base red canopies frnt hedges  41.781818 -71.403718  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATH = os.path.join('.', 'inputs', 'e911', 'FACILITY_Sites_E911.shp')\n",
    "\n",
    "# gdf = GeoDataFrame of E911 sites\n",
    "gdf = gpd.read_file(FILEPATH)\n",
    "gdf['Latitude'] = gdf.geometry.y\n",
    "gdf['Longitude'] = gdf.geometry.x\n",
    "\n",
    "# Limit E911 sites to Providence\n",
    "gdf = gdf[gdf['MSAGComm'] == 'PROVIDENCE']\n",
    "\n",
    "# Standardize street names\n",
    "gdf['St_Full'] = gdf['St_Full'].str.lower().str.strip()\n",
    "gdf['St_Name'] = gdf['St_Name'].str.lower().str.strip()\n",
    "\n",
    "print(\"All columns:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "# View columns of interest\n",
    "to_view = ['Add_Full', 'Add_Number', 'St_Full', 'St_Name', 'St_Alias1', 'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments', 'Latitude', 'Longitude']\n",
    "gdf[to_view].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_address(address):\n",
    "    \"\"\"Categorizes locations by type and extracts necessary compononents for geocoding\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address : str\n",
    "        a singular value from the 'location' column of the case logs DataFrame\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple[int, list[str]]\n",
    "        1. an integer value indicating the address category\n",
    "              0 = Block\n",
    "              1 = Intersection\n",
    "              2 = Landmark\n",
    "        2. Address components needed to geocode the location\n",
    "              [block_number, street_name] for category 0\n",
    "              [street_name1, street_name2] for category 1\n",
    "              address (the input parameter) for category 2\n",
    "    \"\"\"\n",
    "    # Handles rare case where location == nan\n",
    "    if not isinstance(address, str):\n",
    "       return (None, [])\n",
    "\n",
    "    # Define block locations as having a number followed by 'Block', followed by any combination\n",
    "    # of alphanumeric characters and spaces\n",
    "    block_pattern = r'(\\d+)\\s+Block\\s+([\\dA-Za-z\\s\\']+)'\n",
    "\n",
    "    # Define intersection locations as having any combination of alphanumeric characters and spaces\n",
    "    # separated by 'AND', '&', or 'CORNER OF'\n",
    "    address = address.replace(' AND ', ' & ').replace('CORNER OF ', '')\n",
    "    intersection_pattern = r'([\\dA-Za-z\\s]+)\\s*&\\s*([\\dA-Za-z\\s]+)'\n",
    "\n",
    "    # Check if the address matches the block format\n",
    "    block_match = re.match(block_pattern, address)\n",
    "    if block_match:\n",
    "        block_number = block_match.group(1)\n",
    "        street_name = block_match.group(2).strip().lower()\n",
    "        return (0, (block_number, street_name))\n",
    "\n",
    "    # Check if the address matches the intersection format\n",
    "    intersection_match = re.match(intersection_pattern, address)\n",
    "    if intersection_match:\n",
    "        street_name1 = intersection_match.group(1).strip().lower()\n",
    "        street_name2 = intersection_match.group(2).strip().lower()\n",
    "        return (1, (street_name1, street_name2))\n",
    "\n",
    "    # If the address does not match either format, treat it as a landmark\n",
    "    return (2, address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_providence(latitude, longitude):\n",
    "    # Load the GeoDataFrame containing the polygon from the GeoPackage file\n",
    "    gdf_polygon = gpd.read_file(os.path.join('.', 'inputs', 'pvd_boundary.gpkg'), layer='pvd_boundary')\n",
    "    buffer_distance = 0.001\n",
    "    gdf_polygon = gdf_polygon['geometry'].iloc[0].buffer(buffer_distance)\n",
    "\n",
    "    # Create a Point geometry from the given latitude and longitude\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    # Check if the point is within the polygon\n",
    "    result = point.within(gdf_polygon)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert street names to E911 format\n",
    "number_to_words = {\n",
    "      '1st': 'first',\n",
    "      '2nd': 'second',\n",
    "      '3rd': 'third',\n",
    "      '4th': 'fourth',\n",
    "      '5th': 'fifth',\n",
    "      '6th': 'sixth',\n",
    "      '7th': 'seventh',\n",
    "      '8th': 'eighth',\n",
    "      '9th': 'ninth',\n",
    "      '10th': 'tenth',\n",
    "      '11th': 'eleventh',\n",
    "      '12th': 'twelfth',\n",
    "      '13th': 'thirteenth',\n",
    "      '14th': 'fourteenth',\n",
    "      '15th': 'fifteenth',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get block coordinates\n",
    "def get_block_coordinates(components, midpoint):\n",
    "    block, street = components\n",
    "    block = int(block)\n",
    "    stsuffix_to_abbr = {\n",
    "        'avenue': 'av',\n",
    "        'ave': 'av',\n",
    "        'street': 'st',\n",
    "        'terrace': 'terr',\n",
    "        'ter': 'terr',\n",
    "        'boulevard': 'blvd',\n",
    "        'drive': 'dr',\n",
    "        'road': 'rd',\n",
    "        'way': 'wy',\n",
    "        'lane': 'ln',\n",
    "        'court': 'ct',\n",
    "        'place': 'pl',\n",
    "        'parkway': 'pkwy',\n",
    "        'square': 'sq',\n",
    "        'walk': 'wk',\n",
    "        'plaza': 'plz',\n",
    "        'circle': 'cir'}\n",
    "\n",
    "    # Standardize street name to match E911 format\n",
    "    # Need to account for cases where streets are written slightly differently (ex. 'street' vs 'st', 'ave' vs 'av)\n",
    "    street = street.lower().strip()\n",
    "    # Remove periods from street names\n",
    "    street = street.replace('.', '')\n",
    "    street = street + ' '\n",
    "    # Reformat street suffixes\n",
    "    for k, v in stsuffix_to_abbr.items():\n",
    "        street = street.replace(f\" {k} \", f\" {v} \")\n",
    "    # Spell out numerical street names\n",
    "    for k, v in number_to_words.items():\n",
    "        street = street.replace(k, v)\n",
    "    # Remove trailing space\n",
    "    street = street.rstrip()\n",
    "\n",
    "    # Find E911 sites with matching street names / street name aliases\n",
    "    df = gdf[(gdf['St_Full'] == street) | (gdf['St_Alias1'] == street) | (gdf['St_Alias2'] == street) | (gdf['St_Alias3'] == street) | (gdf['St_Alias4'] == street) | (gdf['St_Alias5'] == street)]\n",
    "\n",
    "    # Try a more flexible strategy if no matches are returned\n",
    "    if len(df) == 0:\n",
    "        # Handle case where crime log location contains extra words/characters\n",
    "        def filter_fn(row):\n",
    "            if row['St_Full']:\n",
    "                # Remove apostrophes to minimize inconsistencies (e.g. \"o'connell\" vs \"oconnell\")\n",
    "                if row['St_Full'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                    return True\n",
    "            return False\n",
    "        df_temp = gdf[gdf.apply(filter_fn, axis=1)]\n",
    "        if len(df_temp) > 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            # Handle case where street suffix is missing\n",
    "            def filter_fn2(row):\n",
    "                if row['St_Name']:\n",
    "                    if row['St_Name'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                        return True\n",
    "                return False\n",
    "            df_temp = gdf[gdf.apply(filter_fn2, axis=1)]\n",
    "            df_temp = df_temp[(df_temp['Add_Number'] >= block) & (df_temp['Add_Number'] < block + 100) & (df_temp['Add_Number'] != 0)]\n",
    "            # Verify that there is only one street suffix for the given street name after filtering\n",
    "            if len(df_temp['St_PosType'].unique()) == 1:\n",
    "                df = df_temp\n",
    "        \n",
    "    # Filter E911 sites by block number\n",
    "    # Exclude E911 sites where 'Add_Number'==0; these correspond to E911 sites without address numbers\n",
    "    df = df[(df['Add_Number'] >= block) & (df['Add_Number'] < block + 100) & (df['Add_Number'] != 0)]\n",
    "    df = df.sort_values(by='Add_Number', ascending=True)\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Midpoint method\n",
    "        if midpoint:\n",
    "            latitude = (df['Latitude'].iloc[0] + df['Latitude'].iloc[-1])/2\n",
    "            longitude = (df['Longitude'].iloc[0] + df['Longitude'].iloc[-1])/2\n",
    "\n",
    "        # Middle house method\n",
    "        else:\n",
    "            if len(df) % 2 == 1:\n",
    "                middle_row = df.iloc[df.shape[0] // 2]\n",
    "                latitude = middle_row['Latitude']\n",
    "                longitude = middle_row['Longitude']\n",
    "            else:\n",
    "                middle_two_rows = df.iloc[df.shape[0] // 2 - 1 : df.shape[0] // 2 + 1]\n",
    "                latitude = middle_two_rows['Latitude'].mean()\n",
    "                longitude = middle_two_rows['Longitude'].mean()\n",
    "        return latitude, longitude\n",
    "    return 0, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert from RI State Plane system to WGS 84\n",
    "reproject = Transformer.from_crs(3438, 4326, always_xy=True)\n",
    "\n",
    "# Geocode intersections with RIDOT\n",
    "def get_intersection_coords(address):\n",
    "    base_url_ad='https://risegis.ri.gov/gpserver/rest/services/E911_StreetRange_Locator/GeocodeServer/findAddressCandidates?'\n",
    "    address=address.replace(' & ',' and ')\n",
    "    city='Providence'\n",
    "    try:\n",
    "        add_url=f'Street={address}&City={city}'\n",
    "        data_url = f'{base_url_ad}{add_url}&maxLocations=5&matchOutOfRange=true&WriteXYCoordFields=false&f=pjson'\n",
    "        response=requests.get(data_url)\n",
    "        add_data=response.json()['candidates'] # Collapse the dictionary by one level\n",
    "        if len(add_data)==0:\n",
    "            pass\n",
    "        elif len(add_data)==1:\n",
    "            longitude=add_data[0]['location']['x']\n",
    "            latitude=add_data[0]['location']['y'] \n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "        else:        \n",
    "            all_scores=[]\n",
    "            for m in add_data:\n",
    "                all_scores.append(m['score'])\n",
    "            maxs=max(all_scores) # Find highest score\n",
    "            maxs_idx=all_scores.index(maxs) # And its index (takes 1st highest value if several are equal)\n",
    "            # Get data for highest match and store\n",
    "            longitude=add_data[maxs_idx]['location']['x']\n",
    "            latitude=add_data[maxs_idx]['location']['y']\n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.82497, -71.41162)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load landmark coordinates\n",
    "df_landmark = pd.read_excel(os.path.join('.', 'inputs', 'landmarks.xlsx'))\n",
    "df_landmark['aliases'] = df_landmark['aliases'].astype(str).apply(lambda x: x.split(', '))\n",
    "df_landmark['aliases'] = df_landmark.apply(lambda x: x['aliases'] + [x['location']], axis=1)\n",
    "df_landmark['aliases'] = df_landmark['aliases'].apply(lambda x: [alias.lower() for alias in x])\n",
    "df_by_alias = df_landmark.explode('aliases', ignore_index=True)\n",
    "df_by_alias['aliases'] = df_by_alias['aliases'].drop_duplicates()\n",
    "\n",
    "def is_street(address):\n",
    "    address = address.lower().strip()\n",
    "    street_indicators = [' street', ' st',  ' st.', ' ave', ' av', ' avenue', ' blvd', ' rd', ' way', ' dr']\n",
    "    for indicator in street_indicators:\n",
    "        if address.endswith(indicator):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_landmark_coords(address):\n",
    "    if isinstance(address, float):\n",
    "        return 0, 0\n",
    "    try:\n",
    "        row = df_by_alias[df_by_alias['aliases'] == address.lower().strip()]\n",
    "        #lat = float(row['latitude'])\n",
    "        #long = float(row['longitude'])\n",
    "        lat = float(row.iloc[0]['latitude'])\n",
    "        long= float(row.iloc[0]['longitude'])\n",
    "        return lat, long\n",
    "    except:\n",
    "        if not is_street(address):\n",
    "            # Print the unrecognized landmark\n",
    "            print(address)\n",
    "        return 0, 0\n",
    "\n",
    "# Test\n",
    "get_landmark_coords('kennedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providence boundaries (with 0.005 degree buffer)\n",
    "min_lat = 41.7673\n",
    "max_lat = 41.8668\n",
    "min_long = -71.4774\n",
    "max_long = -71.3719\n",
    "\n",
    "##### Not needed -- in_providence() is used instead #####\n",
    "def within_bounds(latitude, longitude):\n",
    "        \"\"\"Returns True if the coordinates are within the Providence boundaries\"\"\"\n",
    "        if latitude > min_lat and latitude < max_lat and longitude > min_long and longitude < max_long:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, midpoint):\n",
    "    \"\"\"Returns a tuple of numerical (Latitude, Longitude) coordinates in WGS 84\n",
    "    Parameter:\n",
    "              address (string): the 'location' value from the case logs DataFrame\n",
    "              midpoint (boolean): indicates whether the midpoint method should be used in lieu of\n",
    "              the middle house method to calculate block centers\n",
    "              \"\"\"\n",
    "    # Get address category and necessary components for geocoding\n",
    "    category, components = categorize_address(address)\n",
    "\n",
    "    # Geocode block locations\n",
    "    if category == 0:\n",
    "        latitude, longitude = get_block_coordinates(components, midpoint)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'E911'\n",
    "\n",
    "    # Geocode intersection locations\n",
    "    elif category == 1:\n",
    "        latitude, longitude = get_intersection_coords(address)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'RIDOT'\n",
    "\n",
    "    # Geocode landmarks\n",
    "    else:\n",
    "      latitude, longitude = get_landmark_coords(address)\n",
    "      if in_providence(latitude, longitude):\n",
    "         return latitude, longitude, 'Landmark File'\n",
    "              \n",
    "    # Return None if no coordinates are found\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized landmarks (if any):\n",
      "N/A\n",
      "N/A\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "# THIS BLOCK DOES THE PROCESSING (will take time to execute)\n",
    "\n",
    "final_df = results_df.copy()\n",
    "# Set to False to use middle house method for calculating block centers\n",
    "use_midpoint = True\n",
    "\n",
    "print('Unrecognized landmarks (if any):')\n",
    "\n",
    "# Apply our geocoding function to add latitude and longitude columns\n",
    "final_df[['latitude', 'longitude', 'source']] = final_df['location'].apply(lambda x: pd.Series(get_coordinates(x, use_midpoint), dtype=object))\n",
    "# Store records that could not be geocoded\n",
    "no_matches_df = final_df[pd.isnull(final_df['latitude'])]\n",
    "\n",
    "# Store records that were successfully geocoded\n",
    "final_df = final_df[pd.notna(final_df['latitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the landmark file #\n",
    "Update 'landmarks.xlsx' with the appropriate coordinates. Coordinates can be found \n",
    "[here](https://www.openstreetmap.org/search?query=#map=12/41.8173/-71.4231)\n",
    "by searching a location name, right clicking on the map, and selecting \"Show address\".\n",
    "Invalid landmarks can be added to the spreadsheet with the coordinates (0, 0) to suppress future \n",
    "print statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 records successfully geocoded\n",
      "825 records could not be geocoded\n"
     ]
    }
   ],
   "source": [
    "print(len(final_df), \"records successfully geocoded\")\n",
    "print(len(no_matches_df), \"records could not be geocoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00103173</td>\n",
       "      <td>DEAN ST / SPRUCE ST</td>\n",
       "      <td>2025-12-30T23:53:23.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "      <td>2025-00103173-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-00103047</td>\n",
       "      <td>SHILOH ST</td>\n",
       "      <td>2025-12-30T12:27:10.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ACommendatore</td>\n",
       "      <td>2025-00103047-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2025-00102891</td>\n",
       "      <td>100 Block RANDALL SQ</td>\n",
       "      <td>2025-12-29T18:12:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>2025-00102891-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2025-00102864</td>\n",
       "      <td>FENNER ST</td>\n",
       "      <td>2025-12-29T15:51:03.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00102864-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2025-00102704</td>\n",
       "      <td>600 BlockN MAIN ST</td>\n",
       "      <td>2025-12-28T17:43:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>2025-00102704-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber              location            reported_date month  year  \\\n",
       "2   2025-00103173   DEAN ST / SPRUCE ST  2025-12-30T23:53:23.000    12  2025   \n",
       "18  2025-00103047             SHILOH ST  2025-12-30T12:27:10.000    12  2025   \n",
       "50  2025-00102891  100 Block RANDALL SQ  2025-12-29T18:12:00.000    12  2025   \n",
       "55  2025-00102864             FENNER ST  2025-12-29T15:51:03.000    12  2025   \n",
       "74  2025-00102704    600 BlockN MAIN ST  2025-12-28T17:43:00.000    12  2025   \n",
       "\n",
       "                  offense_desc statute_code  \\\n",
       "2   Larceny from Motor Vehicle      11-41-1   \n",
       "18                   Vandalism      11-44-1   \n",
       "50         Assault, Aggravated       11-5-2   \n",
       "55  Larceny from Motor Vehicle      11-41-1   \n",
       "74             Assault, Simple       11-5-3   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "2                   LARCENY/U $1500 - FROM MV      1           HViruet   \n",
       "18     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ACommendatore   \n",
       "50  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1         PHourahan   \n",
       "55                  LARCENY/U $1500 - FROM MV      1   Central Station   \n",
       "74                  SIMPLE ASSAULT OR BATTERY      1         PHourahan   \n",
       "\n",
       "            unique_id violent_cat property_cat  latitude  longitude source  \n",
       "2   2025-00103173-001         NaN          NaN       NaN        NaN   None  \n",
       "18  2025-00103047-001         NaN          NaN       NaN        NaN   None  \n",
       "50  2025-00102891-001         NaN          NaN       NaN        NaN   None  \n",
       "55  2025-00102864-001         NaN          NaN       NaN        NaN   None  \n",
       "74  2025-00102704-001         NaN          NaN       NaN        NaN   None  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    final_df_copy = final_df\n",
    "# Concatenate past and present DFs\n",
    "else:\n",
    "    final_df_copy = pd.concat((past_df, final_df), axis=0, ignore_index=True)\n",
    "\n",
    "# Assign unique IDs to each offense\n",
    "casenum_counts = {casenum: 0 for casenum in final_df_copy['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    # Add 3 digits to each original case number\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "final_df_copy['unique_id'] = final_df_copy.apply(generate_unique_id, axis=1)\n",
    "\n",
    "# Do the same for unmatched locations\n",
    "if exclude_past_no_match and not geocode_all:\n",
    "    # Add new list to previous list of no matches\n",
    "    no_matches_df_new = pd.concat((past_no_matches, no_matches_df))\n",
    "else:\n",
    "    # If we tried to geocode the previous list of no matches, we don't need to add it again\n",
    "    # Concatenate with old list of no matches\n",
    "    no_matches_df_new = pd.concat((no_matches_df, past_no_matches[~past_no_matches['year'].isin(years)]))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "casenum_counts = {casenum: 0 for casenum in no_matches_df_new['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "no_matches_df_new['unique_id'] = no_matches_df_new.apply(generate_unique_id, axis=1)\n",
    "no_matches_df_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the crime categorization file\n",
    "If any unrecognized offense descriptions are printed out, open 'crime_cats.xlsx' and\n",
    "manually enter the new offense descriptions along with their appropriate crime\n",
    "categorizations. Then, rerun this cell and all following cells; \n",
    "no unrecognized offense descriptions should be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00103173</td>\n",
       "      <td>DEAN ST / SPRUCE ST</td>\n",
       "      <td>2025-12-30T23:53:23.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>HViruet</td>\n",
       "      <td>2025-00103173-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larceny-theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-00103047</td>\n",
       "      <td>SHILOH ST</td>\n",
       "      <td>2025-12-30T12:27:10.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ACommendatore</td>\n",
       "      <td>2025-00103047-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2025-00102891</td>\n",
       "      <td>100 Block RANDALL SQ</td>\n",
       "      <td>2025-12-29T18:12:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>2025-00102891-001</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2025-00102864</td>\n",
       "      <td>FENNER ST</td>\n",
       "      <td>2025-12-29T15:51:03.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny from Motor Vehicle</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM MV</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00102864-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larceny-theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2025-00102704</td>\n",
       "      <td>600 BlockN MAIN ST</td>\n",
       "      <td>2025-12-28T17:43:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>PHourahan</td>\n",
       "      <td>2025-00102704-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber              location            reported_date month  year  \\\n",
       "2   2025-00103173   DEAN ST / SPRUCE ST  2025-12-30T23:53:23.000    12  2025   \n",
       "18  2025-00103047             SHILOH ST  2025-12-30T12:27:10.000    12  2025   \n",
       "50  2025-00102891  100 Block RANDALL SQ  2025-12-29T18:12:00.000    12  2025   \n",
       "55  2025-00102864             FENNER ST  2025-12-29T15:51:03.000    12  2025   \n",
       "74  2025-00102704    600 BlockN MAIN ST  2025-12-28T17:43:00.000    12  2025   \n",
       "\n",
       "                  offense_desc statute_code  \\\n",
       "2   Larceny from Motor Vehicle      11-41-1   \n",
       "18                   Vandalism      11-44-1   \n",
       "50         Assault, Aggravated       11-5-2   \n",
       "55  Larceny from Motor Vehicle      11-41-1   \n",
       "74             Assault, Simple       11-5-3   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "2                   LARCENY/U $1500 - FROM MV      1           HViruet   \n",
       "18     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ACommendatore   \n",
       "50  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1         PHourahan   \n",
       "55                  LARCENY/U $1500 - FROM MV      1   Central Station   \n",
       "74                  SIMPLE ASSAULT OR BATTERY      1         PHourahan   \n",
       "\n",
       "            unique_id         violent_cat   property_cat  latitude  longitude  \\\n",
       "2   2025-00103173-001                 NaN  Larceny-theft       NaN        NaN   \n",
       "18  2025-00103047-001                 NaN            NaN       NaN        NaN   \n",
       "50  2025-00102891-001  Aggravated Assault            NaN       NaN        NaN   \n",
       "55  2025-00102864-001                 NaN  Larceny-theft       NaN        NaN   \n",
       "74  2025-00102704-001                 NaN            NaN       NaN        NaN   \n",
       "\n",
       "   source  \n",
       "2    None  \n",
       "18   None  \n",
       "50   None  \n",
       "55   None  \n",
       "74   None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('inputs' ,'crime_cats.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create dictionaries\n",
    "vc = dict(zip(df['offense_desc'], df['violent_cat']))\n",
    "pc = dict(zip(df['offense_desc'], df['property_cat']))\n",
    "\n",
    "def get_categories(offense_desc):\n",
    "    if offense_desc in vc:\n",
    "        return vc[offense_desc], pc[offense_desc]\n",
    "    else:\n",
    "        print('Unrecognized offense description:', offense_desc)\n",
    "        return None, None\n",
    "categorized = final_df_copy.copy()\n",
    "categorized[['violent_cat', 'property_cat']] = categorized['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "no_matches_df_new[['violent_cat', 'property_cat']] = no_matches_df_new['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "no_matches_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches_df_new = no_matches_df_new.drop(columns=['latitude', 'longitude', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:14: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reported_date' to 'reported_d'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'offense_desc' to 'offense_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_code' to 'statute_co'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_desc' to 'statute_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reporting_officer' to 'reporting_'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'violent_cat' to 'violent_ca'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'property_cat' to 'property_c'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reported_date' to 'reported_d'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'offense_desc' to 'offense_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_code' to 'statute_co'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_desc' to 'statute_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reporting_officer' to 'reporting_'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'violent_cat' to 'violent_ca'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'property_cat' to 'property_c'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reported_date' to 'reported_d'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'offense_desc' to 'offense_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_code' to 'statute_co'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_desc' to 'statute_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reporting_officer' to 'reporting_'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'violent_cat' to 'violent_ca'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'property_cat' to 'property_c'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_19160\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reported_date' to 'reported_d'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'offense_desc' to 'offense_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_code' to 'statute_co'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'statute_desc' to 'statute_de'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'reporting_officer' to 'reporting_'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'violent_cat' to 'violent_ca'\n",
      "  ogr_write(\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'property_cat' to 'property_c'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '..\\\\outputs\\\\2025\\\\pvd_non_geocoded_2025.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m year_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(year), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpvd_geocoded_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m no_matches_year_df \u001b[38;5;241m=\u001b[39m no_matches_df_new[no_matches_df_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m year]\n\u001b[1;32m---> 40\u001b[0m no_matches_year_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(year), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpvd_non_geocoded_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3987\u001b[0m     path_or_buf,\n\u001b[0;32m   3988\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3989\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3990\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3991\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3992\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3993\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3994\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3995\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3996\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3997\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3998\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3999\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   4000\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   4001\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   4002\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   4003\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '..\\\\outputs\\\\2025\\\\pvd_non_geocoded_2025.csv'"
     ]
    }
   ],
   "source": [
    "final_df = categorized\n",
    "final_df['year'] = final_df['year'].astype(int)\n",
    "no_matches_df_new['year'] = no_matches_df_new['year'].astype(int)\n",
    "\n",
    "reproject = Transformer.from_crs(4326, 3438, always_xy=True)\n",
    "\n",
    "overwrite_files = True\n",
    "if overwrite_files:\n",
    "    # Shapefile should be in RI State Plane system\n",
    "    long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "    shp_df = gpd.GeoDataFrame(final_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "\n",
    "    # Save the GeoDataFrame to a Shapefile\n",
    "    shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
    "\n",
    "    # Save separate Shapefiles by year\n",
    "    for year in final_df['year'].unique():\n",
    "        try: \n",
    "            # Make a new directory for the year if it doesn't already exist\n",
    "            os.mkdir(os.path.join(\"..\", \"outputs\", str(year)))\n",
    "        except:\n",
    "            pass\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "        shp_df = gpd.GeoDataFrame(year_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "        shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
    "\n",
    "    # Save the DataFrame to a CSV\n",
    "    #final_df = final_df.drop(columns=['geometry'])\n",
    "    final_df.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save the locations we have failed to geocode\n",
    "    no_matches_df_new.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_non_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save separate CSV files by year (excludes past years not included in the new data)\n",
    "    for year in years:\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.csv\"), index=False)\n",
    "        no_matches_year_df = no_matches_df_new[no_matches_df_new['year'] == year]\n",
    "        no_matches_year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_non_geocoded_{year}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
