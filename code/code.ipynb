{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, pandas as pd, geopandas as gpd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False while testing code, should be True for updates\n",
    "overwrite_files = True\n",
    "\n",
    "# Set to True to geocode all locations (including those that have already been geocoded) from scratch\n",
    "# Only used to ensure consistency of coordinate sources if geocoding method changes\n",
    "geocode_all = False # Should stay False for efficiency\n",
    "\n",
    "# Set to False to re-attempt geocoding for previously unmatched locations from the last 180 days\n",
    "exclude_past_no_match = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recent data (last 180 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6651 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-00002270</td>\n",
       "      <td>700 Block WESTMINSTER ST</td>\n",
       "      <td>2025-01-10T01:53:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Traffic Violation</td>\n",
       "      <td>31-26-2</td>\n",
       "      <td>Duty to Stop in Accidents Resulting in Damage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>TCalandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-00002275</td>\n",
       "      <td>100 Block MICHIGAN AVE</td>\n",
       "      <td>2025-01-10T01:51:22.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2.1</td>\n",
       "      <td>FELONY ASSAULT/USE DEVICE SIMILAR TO FIREARM</td>\n",
       "      <td>1</td>\n",
       "      <td>CNicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00002255</td>\n",
       "      <td>CARPENTER ST &amp;  RINGGOLD ST</td>\n",
       "      <td>2025-01-10T00:38:30.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Drug Offenses</td>\n",
       "      <td>21-28-4.01-C1A</td>\n",
       "      <td>POSSESSION OF SCHEDULE I II III</td>\n",
       "      <td>1</td>\n",
       "      <td>ARosales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-00002202</td>\n",
       "      <td>300 Block WESTMINSTER ST</td>\n",
       "      <td>2025-01-09T20:21:24.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>CMain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-00002202</td>\n",
       "      <td>300 Block WESTMINSTER ST</td>\n",
       "      <td>2025-01-09T20:21:24.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>RI Statute Violation</td>\n",
       "      <td>11-32-1</td>\n",
       "      <td>OBSTRUCTING OFFICER IN EXECUTION OF DUTY</td>\n",
       "      <td>1</td>\n",
       "      <td>CMain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      casenumber                     location            reported_date month  \\\n",
       "0  2025-00002270     700 Block WESTMINSTER ST  2025-01-10T01:53:00.000     1   \n",
       "1  2025-00002275       100 Block MICHIGAN AVE  2025-01-10T01:51:22.000     1   \n",
       "2  2025-00002255  CARPENTER ST &  RINGGOLD ST  2025-01-10T00:38:30.000     1   \n",
       "3  2025-00002202     300 Block WESTMINSTER ST  2025-01-09T20:21:24.000     1   \n",
       "4  2025-00002202     300 Block WESTMINSTER ST  2025-01-09T20:21:24.000     1   \n",
       "\n",
       "   year          offense_desc    statute_code  \\\n",
       "0  2025     Traffic Violation         31-26-2   \n",
       "1  2025   Assault, Aggravated        11-5-2.1   \n",
       "2  2025         Drug Offenses  21-28-4.01-C1A   \n",
       "3  2025       Assault, Simple          11-5-3   \n",
       "4  2025  RI Statute Violation         11-32-1   \n",
       "\n",
       "                                        statute_desc counts reporting_officer  \n",
       "0  Duty to Stop in Accidents Resulting in Damage ...      1         TCalandra  \n",
       "1       FELONY ASSAULT/USE DEVICE SIMILAR TO FIREARM      1         CNicholls  \n",
       "2                    POSSESSION OF SCHEDULE I II III      1          ARosales  \n",
       "3                          SIMPLE ASSAULT OR BATTERY      1             CMain  \n",
       "4           OBSTRUCTING OFFICER IN EXECUTION OF DUTY      1             CMain  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that limit defaults to 1000\n",
    "data_url='https://data.providenceri.gov/resource/rz3y-pz8v.json?%24limit=20000'\n",
    "response=requests.get(data_url)\n",
    "results = response.json()\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df['year'] = results_df['year'].astype(int)\n",
    "years = results_df['year'].unique()\n",
    "\n",
    "print(len(results_df), \"rows\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully geocoded records\n",
    "past_df = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_geocoded.csv'))\n",
    "past_df['year'] = past_df['year'].astype(int)\n",
    "\n",
    "# Records that could not be geocoded\n",
    "past_no_matches = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_non_geocoded.csv'))\n",
    "past_no_matches['year'] = past_no_matches['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-00500073</td>\n",
       "      <td>RIVER HOUSE, 1 POINT ST</td>\n",
       "      <td>2025-01-09T17:06:50.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00500070</td>\n",
       "      <td>WASHINGTON ST</td>\n",
       "      <td>2025-01-09T13:23:48.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00002076</td>\n",
       "      <td>LANCASHIRE ST</td>\n",
       "      <td>2025-01-09T11:14:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/O $11000 - AUTO THEFT</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-00001913</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2025-01-08T17:23:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2025-00500059</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2025-01-08T16:01:49.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - OTH LAR</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "10  2025-00500073      RIVER HOUSE, 1 POINT ST  2025-01-09T17:06:50.000     1   \n",
       "19  2025-00500070                WASHINGTON ST  2025-01-09T13:23:48.000     1   \n",
       "21  2025-00002076                LANCASHIRE ST  2025-01-09T11:14:00.000     1   \n",
       "37  2025-00001913  0 Block PLEASANT VALLEY PKY  2025-01-08T17:23:00.000     1   \n",
       "42  2025-00500059                 HARTFORD AVE  2025-01-08T16:01:49.000     1   \n",
       "\n",
       "    year            offense_desc statute_code                    statute_desc  \\\n",
       "10  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "19  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "21  2025     Motor Vehicle Theft      11-41-1   LARCENY/O $11000 - AUTO THEFT   \n",
       "37  2025  Request for Assistance     Not Used                   No violations   \n",
       "42  2025          Larceny, Other      11-41-1       LARCENY/U $1500 - OTH LAR   \n",
       "\n",
       "   counts reporting_officer unique_id violent_cat property_cat  \n",
       "10      1            NField       NaN         NaN          NaN  \n",
       "19      1            NField       NaN         NaN          NaN  \n",
       "21      1   Central Station       NaN         NaN          NaN  \n",
       "37      0   Central Station       NaN         NaN          NaN  \n",
       "42      1            NField       NaN         NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    # concatenate past_df, results_df, and past_no_matches\n",
    "    df_all = pd.concat((past_df, results_df, past_no_matches))\n",
    "    # drop dupilcate records\n",
    "    df_all = df_all.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    results_df = df_all\n",
    "else:\n",
    "    df2 = results_df.copy()\n",
    "    # Identify new records by case number and time\n",
    "    df1 = past_df[['casenumber', 'reported_date']]\n",
    "\n",
    "    if exclude_past_no_match:\n",
    "        # Exclude past locations which returned no location matches\n",
    "        df1 = pd.concat((df1, past_no_matches[['casenumber', 'reported_date']]))\n",
    "    else:\n",
    "        # Add previously unmatched locations to the df to attempt geocoding again\n",
    "        df2 = pd.concat((df2, past_no_matches[past_no_matches['year'].isin(years)]))\n",
    "        df2 = df2.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    merged = df2.merge(df1, on=['casenumber', 'reported_date'], how='left', indicator=True)\n",
    "\n",
    "    # Identify new case records\n",
    "    new_records = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    # results_df is the DataFrame which will be geocoded\n",
    "    results_df = new_records\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load E911 data\n",
    "(needed to geocode block locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:\n",
      "Index(['SiteType', 'Site_GUID', 'Add_Full', 'AddNumFull', 'AddNum_Pre',\n",
      "       'Add_Number', 'AddNum_Suf', 'St_Full', 'St_PreMod', 'St_PreDir',\n",
      "       'St_PreTyp', 'St_Name', 'St_PosType', 'St_PosDir', 'St_PosMod',\n",
      "       'MSAGComm', 'ESN', 'State', 'Post_Code', 'Country', 'St_Alias1',\n",
      "       'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments',\n",
      "       'DateUpdate', 'geometry', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Add_Full</th>\n",
       "      <th>Add_Number</th>\n",
       "      <th>St_Full</th>\n",
       "      <th>St_Name</th>\n",
       "      <th>St_Alias1</th>\n",
       "      <th>St_Alias2</th>\n",
       "      <th>St_Alias3</th>\n",
       "      <th>St_Alias4</th>\n",
       "      <th>St_Alias5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>121 FARMINGTON AV</td>\n",
       "      <td>121.0</td>\n",
       "      <td>farmington av</td>\n",
       "      <td>farmington</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2 stry lght blu wht trm frnt prch blk rail</td>\n",
       "      <td>41.805353</td>\n",
       "      <td>-71.459654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>2 DEERFIELD TERR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>brwn shngles 2stry wht trim</td>\n",
       "      <td>41.785448</td>\n",
       "      <td>-71.420708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>3 DEERFIELD TERR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2stry wht split blk shttrs frnt prch</td>\n",
       "      <td>41.785195</td>\n",
       "      <td>-71.420797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37275</th>\n",
       "      <td>98 CYR ST</td>\n",
       "      <td>98.0</td>\n",
       "      <td>cyr st</td>\n",
       "      <td>cyr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tan brck 1stry wht trim brwn shttrs R grg, see VC</td>\n",
       "      <td>41.785209</td>\n",
       "      <td>-71.404274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37308</th>\n",
       "      <td>179 WHEELER AV</td>\n",
       "      <td>179.0</td>\n",
       "      <td>wheeler av</td>\n",
       "      <td>wheeler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>grey 3stry red brck base red canopies frnt hedges</td>\n",
       "      <td>41.781818</td>\n",
       "      <td>-71.403718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Add_Full  Add_Number         St_Full     St_Name St_Alias1  \\\n",
       "30282  121 FARMINGTON AV       121.0   farmington av  farmington      None   \n",
       "37261   2 DEERFIELD TERR         2.0  deerfield terr   deerfield      None   \n",
       "37262   3 DEERFIELD TERR         3.0  deerfield terr   deerfield      None   \n",
       "37275          98 CYR ST        98.0          cyr st         cyr      None   \n",
       "37308     179 WHEELER AV       179.0      wheeler av     wheeler      None   \n",
       "\n",
       "      St_Alias2 St_Alias3 St_Alias4 St_Alias5  \\\n",
       "30282      None      None      None      None   \n",
       "37261      None      None      None      None   \n",
       "37262      None      None      None      None   \n",
       "37275      None      None      None      None   \n",
       "37308      None      None      None      None   \n",
       "\n",
       "                                                Comments   Latitude  Longitude  \n",
       "30282         2 stry lght blu wht trm frnt prch blk rail  41.805353 -71.459654  \n",
       "37261                        brwn shngles 2stry wht trim  41.785448 -71.420708  \n",
       "37262               2stry wht split blk shttrs frnt prch  41.785195 -71.420797  \n",
       "37275  tan brck 1stry wht trim brwn shttrs R grg, see VC  41.785209 -71.404274  \n",
       "37308  grey 3stry red brck base red canopies frnt hedges  41.781818 -71.403718  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATH = os.path.join('.', 'inputs', 'e911', 'FACILITY_Sites_E911.shp')\n",
    "\n",
    "# gdf = GeoDataFrame of E911 sites\n",
    "gdf = gpd.read_file(FILEPATH)\n",
    "gdf['Latitude'] = gdf.geometry.y\n",
    "gdf['Longitude'] = gdf.geometry.x\n",
    "\n",
    "# Limit E911 sites to Providence\n",
    "gdf = gdf[gdf['MSAGComm'] == 'PROVIDENCE']\n",
    "\n",
    "# Standardize street names\n",
    "gdf['St_Full'] = gdf['St_Full'].str.lower().str.strip()\n",
    "gdf['St_Name'] = gdf['St_Name'].str.lower().str.strip()\n",
    "\n",
    "print(\"All columns:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "# View columns of interest\n",
    "to_view = ['Add_Full', 'Add_Number', 'St_Full', 'St_Name', 'St_Alias1', 'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments', 'Latitude', 'Longitude']\n",
    "gdf[to_view].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_address(address):\n",
    "    \"\"\"Categorizes locations by type and extracts necessary compononents for geocoding\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address : str\n",
    "        a singular value from the 'location' column of the case logs DataFrame\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple[int, list[str]]\n",
    "        1. an integer value indicating the address category\n",
    "              0 = Block\n",
    "              1 = Intersection\n",
    "              2 = Landmark\n",
    "        2. Address components needed to geocode the location\n",
    "              [block_number, street_name] for category 0\n",
    "              [street_name1, street_name2] for category 1\n",
    "              address (the input parameter) for category 2\n",
    "    \"\"\"\n",
    "    # Handles rare case where location == nan\n",
    "    if not isinstance(address, str):\n",
    "       return (None, [])\n",
    "\n",
    "    # Define block locations as having a number followed by 'Block', followed by any combination\n",
    "    # of alphanumeric characters and spaces\n",
    "    block_pattern = r'(\\d+)\\s+Block\\s+([\\dA-Za-z\\s\\']+)'\n",
    "\n",
    "    # Define intersection locations as having any combination of alphanumeric characters and spaces\n",
    "    # separated by 'AND', '&', or 'CORNER OF'\n",
    "    address = address.replace(' AND ', ' & ').replace('CORNER OF ', '')\n",
    "    intersection_pattern = r'([\\dA-Za-z\\s]+)\\s*&\\s*([\\dA-Za-z\\s]+)'\n",
    "\n",
    "    # Check if the address matches the block format\n",
    "    block_match = re.match(block_pattern, address)\n",
    "    if block_match:\n",
    "        block_number = block_match.group(1)\n",
    "        street_name = block_match.group(2).strip().lower()\n",
    "        return (0, (block_number, street_name))\n",
    "\n",
    "    # Check if the address matches the intersection format\n",
    "    intersection_match = re.match(intersection_pattern, address)\n",
    "    if intersection_match:\n",
    "        street_name1 = intersection_match.group(1).strip().lower()\n",
    "        street_name2 = intersection_match.group(2).strip().lower()\n",
    "        return (1, (street_name1, street_name2))\n",
    "\n",
    "    # If the address does not match either format, treat it as a landmark\n",
    "    return (2, address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_providence(latitude, longitude):\n",
    "    # Load the GeoDataFrame containing the polygon from the GeoPackage file\n",
    "    gdf_polygon = gpd.read_file(os.path.join('.', 'inputs', 'pvd_boundary.gpkg'), layer='pvd_boundary')\n",
    "    buffer_distance = 0.001\n",
    "    gdf_polygon = gdf_polygon['geometry'].iloc[0].buffer(buffer_distance)\n",
    "\n",
    "    # Create a Point geometry from the given latitude and longitude\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    # Check if the point is within the polygon\n",
    "    result = point.within(gdf_polygon)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert street names to E911 format\n",
    "number_to_words = {\n",
    "      '1st': 'first',\n",
    "      '2nd': 'second',\n",
    "      '3rd': 'third',\n",
    "      '4th': 'fourth',\n",
    "      '5th': 'fifth',\n",
    "      '6th': 'sixth',\n",
    "      '7th': 'seventh',\n",
    "      '8th': 'eighth',\n",
    "      '9th': 'ninth',\n",
    "      '10th': 'tenth',\n",
    "      '11th': 'eleventh',\n",
    "      '12th': 'twelfth',\n",
    "      '13th': 'thirteenth',\n",
    "      '14th': 'fourteenth',\n",
    "      '15th': 'fifteenth',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get block coordinates\n",
    "def get_block_coordinates(components, midpoint):\n",
    "    block, street = components\n",
    "    block = int(block)\n",
    "    stsuffix_to_abbr = {\n",
    "        'avenue': 'av',\n",
    "        'ave': 'av',\n",
    "        'street': 'st',\n",
    "        'terrace': 'terr',\n",
    "        'ter': 'terr',\n",
    "        'boulevard': 'blvd',\n",
    "        'drive': 'dr',\n",
    "        'road': 'rd',\n",
    "        'way': 'wy',\n",
    "        'lane': 'ln',\n",
    "        'court': 'ct',\n",
    "        'place': 'pl',\n",
    "        'parkway': 'pkwy',\n",
    "        'square': 'sq',\n",
    "        'walk': 'wk',\n",
    "        'plaza': 'plz',\n",
    "        'circle': 'cir'}\n",
    "\n",
    "    # Standardize street name to match E911 format\n",
    "    # Need to account for cases where streets are written slightly differently (ex. 'street' vs 'st', 'ave' vs 'av)\n",
    "    street = street.lower().strip()\n",
    "    # Remove periods from street names\n",
    "    street = street.replace('.', '')\n",
    "    street = street + ' '\n",
    "    # Reformat street suffixes\n",
    "    for k, v in stsuffix_to_abbr.items():\n",
    "        street = street.replace(f\" {k} \", f\" {v} \")\n",
    "    # Spell out numerical street names\n",
    "    for k, v in number_to_words.items():\n",
    "        street = street.replace(k, v)\n",
    "    # Remove trailing space\n",
    "    street = street.rstrip()\n",
    "\n",
    "    # Find E911 sites with matching street names / street name aliases\n",
    "    df = gdf[(gdf['St_Full'] == street) | (gdf['St_Alias1'] == street) | (gdf['St_Alias2'] == street) | (gdf['St_Alias3'] == street) | (gdf['St_Alias4'] == street) | (gdf['St_Alias5'] == street)]\n",
    "\n",
    "    # Try a more flexible strategy if no matches are returned\n",
    "    if len(df) == 0:\n",
    "        # Handle case where crime log location contains extra words/characters\n",
    "        def filter_fn(row):\n",
    "            if row['St_Full']:\n",
    "                # Remove apostrophes to minimize inconsistencies (e.g. \"o'connell\" vs \"oconnell\")\n",
    "                if row['St_Full'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                    return True\n",
    "            return False\n",
    "        df_temp = gdf[gdf.apply(filter_fn, axis=1)]\n",
    "        if len(df_temp) > 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            # Handle case where street suffix is missing\n",
    "            def filter_fn2(row):\n",
    "                if row['St_Name']:\n",
    "                    if row['St_Name'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                        return True\n",
    "                return False\n",
    "            df_temp = gdf[gdf.apply(filter_fn2, axis=1)]\n",
    "            df_temp = df_temp[(df_temp['Add_Number'] >= block) & (df_temp['Add_Number'] < block + 100) & (df_temp['Add_Number'] != 0)]\n",
    "            # Verify that there is only one street suffix for the given street name after filtering\n",
    "            if len(df_temp['St_PosType'].unique()) == 1:\n",
    "                df = df_temp\n",
    "        \n",
    "    # Filter E911 sites by block number\n",
    "    # Exclude E911 sites where 'Add_Number'==0; these correspond to E911 sites without address numbers\n",
    "    df = df[(df['Add_Number'] >= block) & (df['Add_Number'] < block + 100) & (df['Add_Number'] != 0)]\n",
    "    df = df.sort_values(by='Add_Number', ascending=True)\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Midpoint method\n",
    "        if midpoint:\n",
    "            latitude = (df['Latitude'].iloc[0] + df['Latitude'].iloc[-1])/2\n",
    "            longitude = (df['Longitude'].iloc[0] + df['Longitude'].iloc[-1])/2\n",
    "\n",
    "        # Middle house method\n",
    "        else:\n",
    "            if len(df) % 2 == 1:\n",
    "                middle_row = df.iloc[df.shape[0] // 2]\n",
    "                latitude = middle_row['Latitude']\n",
    "                longitude = middle_row['Longitude']\n",
    "            else:\n",
    "                middle_two_rows = df.iloc[df.shape[0] // 2 - 1 : df.shape[0] // 2 + 1]\n",
    "                latitude = middle_two_rows['Latitude'].mean()\n",
    "                longitude = middle_two_rows['Longitude'].mean()\n",
    "        return latitude, longitude\n",
    "    return 0, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert from RI State Plane system to WGS 84\n",
    "reproject = Transformer.from_crs(3438, 4326, always_xy=True)\n",
    "\n",
    "# Geocode intersections with RIDOT\n",
    "def get_intersection_coords(address):\n",
    "    base_url_ad='https://risegis.ri.gov/gpserver/rest/services/E911_StreetRange_Locator/GeocodeServer/findAddressCandidates?'\n",
    "    address=address.replace(' & ',' and ')\n",
    "    city='Providence'\n",
    "    try:\n",
    "        add_url=f'Street={address}&City={city}'\n",
    "        data_url = f'{base_url_ad}{add_url}&maxLocations=5&matchOutOfRange=true&WriteXYCoordFields=false&f=pjson'\n",
    "        response=requests.get(data_url)\n",
    "        add_data=response.json()['candidates'] # Collapse the dictionary by one level\n",
    "        if len(add_data)==0:\n",
    "            pass\n",
    "        elif len(add_data)==1:\n",
    "            longitude=add_data[0]['location']['x']\n",
    "            latitude=add_data[0]['location']['y'] \n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "        else:        \n",
    "            all_scores=[]\n",
    "            for m in add_data:\n",
    "                all_scores.append(m['score'])\n",
    "            maxs=max(all_scores) # Find highest score\n",
    "            maxs_idx=all_scores.index(maxs) # And its index (takes 1st highest value if several are equal)\n",
    "            # Get data for highest match and store\n",
    "            longitude=add_data[maxs_idx]['location']['x']\n",
    "            latitude=add_data[maxs_idx]['location']['y']\n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.82497, -71.41162)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load landmark coordinates\n",
    "df_landmark = pd.read_excel(os.path.join('.', 'inputs', 'landmarks.xlsx'))\n",
    "df_landmark['aliases'] = df_landmark['aliases'].astype(str).apply(lambda x: x.split(', '))\n",
    "df_landmark['aliases'] = df_landmark.apply(lambda x: x['aliases'] + [x['location']], axis=1)\n",
    "df_landmark['aliases'] = df_landmark['aliases'].apply(lambda x: [alias.lower() for alias in x])\n",
    "df_by_alias = df_landmark.explode('aliases', ignore_index=True)\n",
    "df_by_alias['aliases'] = df_by_alias['aliases'].drop_duplicates()\n",
    "\n",
    "def is_street(address):\n",
    "    address = address.lower().strip()\n",
    "    street_indicators = [' street', ' st',  ' st.', ' ave', ' av', ' avenue', ' blvd', ' rd', ' way', ' dr']\n",
    "    for indicator in street_indicators:\n",
    "        if address.endswith(indicator):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_landmark_coords(address):\n",
    "    if isinstance(address, float):\n",
    "        return 0, 0\n",
    "    try:\n",
    "        row = df_by_alias[df_by_alias['aliases'] == address.lower().strip()]\n",
    "        #lat = float(row['latitude'])\n",
    "        #long = float(row['longitude'])\n",
    "        lat = float(row.iloc[0]['latitude'])\n",
    "        long= float(row.iloc[0]['longitude'])\n",
    "        return lat, long\n",
    "    except:\n",
    "        if not is_street(address):\n",
    "            # Print the unrecognized landmark\n",
    "            print(address)\n",
    "        return 0, 0\n",
    "\n",
    "# Test\n",
    "get_landmark_coords('kennedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providence boundaries (with 0.005 degree buffer)\n",
    "min_lat = 41.7673\n",
    "max_lat = 41.8668\n",
    "min_long = -71.4774\n",
    "max_long = -71.3719\n",
    "\n",
    "##### Not needed -- in_providence() is used instead #####\n",
    "def within_bounds(latitude, longitude):\n",
    "        \"\"\"Returns True if the coordinates are within the Providence boundaries\"\"\"\n",
    "        if latitude > min_lat and latitude < max_lat and longitude > min_long and longitude < max_long:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, midpoint):\n",
    "    \"\"\"Returns a tuple of numerical (Latitude, Longitude) coordinates in WGS 84\n",
    "    Parameter:\n",
    "              address (string): the 'location' value from the case logs DataFrame\n",
    "              midpoint (boolean): indicates whether the midpoint method should be used in lieu of\n",
    "              the middle house method to calculate block centers\n",
    "              \"\"\"\n",
    "    # Get address category and necessary components for geocoding\n",
    "    category, components = categorize_address(address)\n",
    "\n",
    "    # Geocode block locations\n",
    "    if category == 0:\n",
    "        latitude, longitude = get_block_coordinates(components, midpoint)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'E911'\n",
    "\n",
    "    # Geocode intersection locations\n",
    "    elif category == 1:\n",
    "        latitude, longitude = get_intersection_coords(address)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'RIDOT'\n",
    "\n",
    "    # Geocode landmarks\n",
    "    else:\n",
    "      latitude, longitude = get_landmark_coords(address)\n",
    "      if in_providence(latitude, longitude):\n",
    "         return latitude, longitude, 'Landmark File'\n",
    "              \n",
    "    # Return None if no coordinates are found\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized landmarks (if any):\n"
     ]
    }
   ],
   "source": [
    "# THIS BLOCK DOES THE PROCESSING (will take time to execute)\n",
    "\n",
    "final_df = results_df.copy()\n",
    "# Set to False to use middle house method for calculating block centers\n",
    "use_midpoint = True\n",
    "\n",
    "print('Unrecognized landmarks (if any):')\n",
    "\n",
    "# Apply our geocoding function to add latitude and longitude columns\n",
    "final_df[['latitude', 'longitude', 'source']] = final_df['location'].apply(lambda x: pd.Series(get_coordinates(x, use_midpoint), dtype=object))\n",
    "# Store records that could not be geocoded\n",
    "no_matches_df = final_df[pd.isnull(final_df['latitude'])]\n",
    "\n",
    "# Store records that were successfully geocoded\n",
    "final_df = final_df[pd.notna(final_df['latitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the landmark file #\n",
    "Update 'landmarks.xlsx' with the appropriate coordinates. Coordinates can be found \n",
    "[here](https://www.openstreetmap.org/search?query=#map=12/41.8173/-71.4231)\n",
    "by searching a location name, right clicking on the map, and selecting \"Show address\".\n",
    "Invalid landmarks can be added to the spreadsheet with the coordinates (0, 0) to suppress future \n",
    "print statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 records successfully geocoded\n",
      "621 records could not be geocoded\n"
     ]
    }
   ],
   "source": [
    "print(len(final_df), \"records successfully geocoded\")\n",
    "print(len(no_matches_df), \"records could not be geocoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-00500073</td>\n",
       "      <td>RIVER HOUSE, 1 POINT ST</td>\n",
       "      <td>2025-01-09T17:06:50.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500073-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00500070</td>\n",
       "      <td>WASHINGTON ST</td>\n",
       "      <td>2025-01-09T13:23:48.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500070-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00002076</td>\n",
       "      <td>LANCASHIRE ST</td>\n",
       "      <td>2025-01-09T11:14:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/O $11000 - AUTO THEFT</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00002076-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-00001913</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2025-01-08T17:23:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00001913-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2025-00500059</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2025-01-08T16:01:49.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - OTH LAR</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500059-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "10  2025-00500073      RIVER HOUSE, 1 POINT ST  2025-01-09T17:06:50.000     1   \n",
       "19  2025-00500070                WASHINGTON ST  2025-01-09T13:23:48.000     1   \n",
       "21  2025-00002076                LANCASHIRE ST  2025-01-09T11:14:00.000     1   \n",
       "37  2025-00001913  0 Block PLEASANT VALLEY PKY  2025-01-08T17:23:00.000     1   \n",
       "42  2025-00500059                 HARTFORD AVE  2025-01-08T16:01:49.000     1   \n",
       "\n",
       "    year            offense_desc statute_code                    statute_desc  \\\n",
       "10  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "19  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "21  2025     Motor Vehicle Theft      11-41-1   LARCENY/O $11000 - AUTO THEFT   \n",
       "37  2025  Request for Assistance     Not Used                   No violations   \n",
       "42  2025          Larceny, Other      11-41-1       LARCENY/U $1500 - OTH LAR   \n",
       "\n",
       "   counts reporting_officer          unique_id violent_cat property_cat  \\\n",
       "10      1            NField  2025-00500073-001         NaN          NaN   \n",
       "19      1            NField  2025-00500070-001         NaN          NaN   \n",
       "21      1   Central Station  2025-00002076-001         NaN          NaN   \n",
       "37      0   Central Station  2025-00001913-001         NaN          NaN   \n",
       "42      1            NField  2025-00500059-001         NaN          NaN   \n",
       "\n",
       "    latitude  longitude source  \n",
       "10       NaN        NaN   None  \n",
       "19       NaN        NaN   None  \n",
       "21       NaN        NaN   None  \n",
       "37       NaN        NaN   None  \n",
       "42       NaN        NaN   None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    final_df_copy = final_df\n",
    "# Concatenate past and present DFs\n",
    "else:\n",
    "    final_df_copy = pd.concat((past_df, final_df), axis=0, ignore_index=True)\n",
    "\n",
    "# Assign unique IDs to each offense\n",
    "casenum_counts = {casenum: 0 for casenum in final_df_copy['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    # Add 3 digits to each original case number\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "final_df_copy['unique_id'] = final_df_copy.apply(generate_unique_id, axis=1)\n",
    "\n",
    "# Do the same for unmatched locations\n",
    "if exclude_past_no_match and not geocode_all:\n",
    "    # Add new list to previous list of no matches\n",
    "    no_matches_df_new = pd.concat((past_no_matches, no_matches_df))\n",
    "else:\n",
    "    # If we tried to geocode the previous list of no matches, we don't need to add it again\n",
    "    # Concatenate with old list of no matches\n",
    "    no_matches_df_new = pd.concat((no_matches_df, past_no_matches[~past_no_matches['year'].isin(years)]))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "casenum_counts = {casenum: 0 for casenum in no_matches_df_new['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "no_matches_df_new['unique_id'] = no_matches_df_new.apply(generate_unique_id, axis=1)\n",
    "no_matches_df_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the crime categorization file\n",
    "If any unrecognized offense descriptions are printed out, open 'crime_cats.xlsx' and\n",
    "manually enter the new offense descriptions along with their appropriate crime\n",
    "categorizations. Then, rerun this cell and all following cells; \n",
    "no unrecognized offense descriptions should be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-00500073</td>\n",
       "      <td>RIVER HOUSE, 1 POINT ST</td>\n",
       "      <td>2025-01-09T17:06:50.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500073-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00500070</td>\n",
       "      <td>WASHINGTON ST</td>\n",
       "      <td>2025-01-09T13:23:48.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fraud, Credit Card</td>\n",
       "      <td>11-49-4</td>\n",
       "      <td>FRAUDULENT USE OF CREDIT CARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500070-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00002076</td>\n",
       "      <td>LANCASHIRE ST</td>\n",
       "      <td>2025-01-09T11:14:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/O $11000 - AUTO THEFT</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00002076-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-00001913</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2025-01-08T17:23:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00001913-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2025-00500059</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2025-01-08T16:01:49.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - OTH LAR</td>\n",
       "      <td>1</td>\n",
       "      <td>NField</td>\n",
       "      <td>2025-00500059-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larceny-theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "10  2025-00500073      RIVER HOUSE, 1 POINT ST  2025-01-09T17:06:50.000     1   \n",
       "19  2025-00500070                WASHINGTON ST  2025-01-09T13:23:48.000     1   \n",
       "21  2025-00002076                LANCASHIRE ST  2025-01-09T11:14:00.000     1   \n",
       "37  2025-00001913  0 Block PLEASANT VALLEY PKY  2025-01-08T17:23:00.000     1   \n",
       "42  2025-00500059                 HARTFORD AVE  2025-01-08T16:01:49.000     1   \n",
       "\n",
       "    year            offense_desc statute_code                    statute_desc  \\\n",
       "10  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "19  2025      Fraud, Credit Card      11-49-4  FRAUDULENT USE OF CREDIT CARDS   \n",
       "21  2025     Motor Vehicle Theft      11-41-1   LARCENY/O $11000 - AUTO THEFT   \n",
       "37  2025  Request for Assistance     Not Used                   No violations   \n",
       "42  2025          Larceny, Other      11-41-1       LARCENY/U $1500 - OTH LAR   \n",
       "\n",
       "   counts reporting_officer          unique_id violent_cat  \\\n",
       "10      1            NField  2025-00500073-001         NaN   \n",
       "19      1            NField  2025-00500070-001         NaN   \n",
       "21      1   Central Station  2025-00002076-001         NaN   \n",
       "37      0   Central Station  2025-00001913-001         NaN   \n",
       "42      1            NField  2025-00500059-001         NaN   \n",
       "\n",
       "           property_cat  latitude  longitude source  \n",
       "10                  NaN       NaN        NaN   None  \n",
       "19                  NaN       NaN        NaN   None  \n",
       "21  Motor Vehicle Theft       NaN        NaN   None  \n",
       "37                  NaN       NaN        NaN   None  \n",
       "42        Larceny-theft       NaN        NaN   None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('inputs' ,'crime_cats.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create dictionaries\n",
    "vc = dict(zip(df['offense_desc'], df['violent_cat']))\n",
    "pc = dict(zip(df['offense_desc'], df['property_cat']))\n",
    "\n",
    "def get_categories(offense_desc):\n",
    "    if offense_desc in vc:\n",
    "        return vc[offense_desc], pc[offense_desc]\n",
    "    else:\n",
    "        print('Unrecognized offense description:', offense_desc)\n",
    "        return None, None\n",
    "categorized = final_df_copy.copy()\n",
    "categorized[['violent_cat', 'property_cat']] = categorized['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "no_matches_df_new[['violent_cat', 'property_cat']] = no_matches_df_new['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "no_matches_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches_df_new = no_matches_df_new.drop(columns=['latitude', 'longitude', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:14: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_16332\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n"
     ]
    }
   ],
   "source": [
    "final_df = categorized\n",
    "final_df['year'] = final_df['year'].astype(int)\n",
    "no_matches_df_new['year'] = no_matches_df_new['year'].astype(int)\n",
    "\n",
    "reproject = Transformer.from_crs(4326, 3438, always_xy=True)\n",
    "\n",
    "overwrite_files = True\n",
    "if overwrite_files:\n",
    "    # Shapefile should be in RI State Plane system\n",
    "    long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "    shp_df = gpd.GeoDataFrame(final_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "\n",
    "    # Save the GeoDataFrame to a Shapefile\n",
    "    shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
    "\n",
    "    # Save separate Shapefiles by year\n",
    "    for year in final_df['year'].unique():\n",
    "        try: \n",
    "            # Make a new directory for the year if it doesn't already exist\n",
    "            os.mkdir(os.path.join(\"..\", \"outputs\", str(year)))\n",
    "        except:\n",
    "            pass\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "        shp_df = gpd.GeoDataFrame(year_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "        shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
    "\n",
    "    # Save the DataFrame to a CSV\n",
    "    #final_df = final_df.drop(columns=['geometry'])\n",
    "    final_df.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save the locations we have failed to geocode\n",
    "    no_matches_df_new.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_non_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save separate CSV files by year (excludes past years not included in the new data)\n",
    "    for year in years:\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.csv\"), index=False)\n",
    "        no_matches_year_df = no_matches_df_new[no_matches_df_new['year'] == year]\n",
    "        no_matches_year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_non_geocoded_{year}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
