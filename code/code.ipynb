{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, pandas as pd, geopandas as gpd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False while testing code, should be True for updates\n",
    "overwrite_files = True\n",
    "\n",
    "# Set to True to geocode all locations (including those that have already been geocoded) from scratch\n",
    "# Only used to ensure consistency of coordinate sources if geocoding method changes\n",
    "geocode_all = False # Should stay False for efficiency\n",
    "\n",
    "# Set to False to re-attempt geocoding for previously unmatched locations from the last 180 days\n",
    "exclude_past_no_match = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recent data (last 180 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5778 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-00065735</td>\n",
       "      <td>500 Block EDDY ST</td>\n",
       "      <td>2025-08-19T01:11:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-16</td>\n",
       "      <td>ASSAULT OF HEALTH CARE PROVIDERS OR EMERGENCY ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CNicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-00065727</td>\n",
       "      <td>CRANSTON ST &amp;  HUNTINGTON AVE</td>\n",
       "      <td>2025-08-19T00:43:29.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Warrant\\Capias</td>\n",
       "      <td>BWARRANT-6D</td>\n",
       "      <td>BENCH WARRANT ISSUED FROM 6TH DISTRICT COURT</td>\n",
       "      <td>1</td>\n",
       "      <td>DSchiavulli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-00065725</td>\n",
       "      <td>CRANSTON ST &amp;  HANOVER ST</td>\n",
       "      <td>2025-08-19T00:41:36.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Warrant/Capias</td>\n",
       "      <td>12-9-16</td>\n",
       "      <td>WARRANT OF ARREST ON AFFIDAVIT - NOT RPT TO FBI</td>\n",
       "      <td>1</td>\n",
       "      <td>KMilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-00065702</td>\n",
       "      <td>0 Block PROVIDENCE PL</td>\n",
       "      <td>2025-08-18T23:07:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT/BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADaCruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-00065696</td>\n",
       "      <td>500 Block PUBLIC ST</td>\n",
       "      <td>2025-08-18T22:19:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Disorderly Conduct</td>\n",
       "      <td>11-45-1</td>\n",
       "      <td>DISORDERLY CONDUCT</td>\n",
       "      <td>1</td>\n",
       "      <td>DMonteiro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      casenumber                       location            reported_date  \\\n",
       "0  2025-00065735              500 Block EDDY ST  2025-08-19T01:11:00.000   \n",
       "1  2025-00065727  CRANSTON ST &  HUNTINGTON AVE  2025-08-19T00:43:29.000   \n",
       "2  2025-00065725      CRANSTON ST &  HANOVER ST  2025-08-19T00:41:36.000   \n",
       "3  2025-00065702          0 Block PROVIDENCE PL  2025-08-18T23:07:00.000   \n",
       "4  2025-00065696            500 Block PUBLIC ST  2025-08-18T22:19:00.000   \n",
       "\n",
       "  month  year         offense_desc statute_code  \\\n",
       "0     8  2025  Assault, Aggravated      11-5-16   \n",
       "1     8  2025       Warrant\\Capias  BWARRANT-6D   \n",
       "2     8  2025       Warrant/Capias      12-9-16   \n",
       "3     8  2025      Assault, Simple       11-5-3   \n",
       "4     8  2025   Disorderly Conduct      11-45-1   \n",
       "\n",
       "                                        statute_desc counts reporting_officer  \n",
       "0  ASSAULT OF HEALTH CARE PROVIDERS OR EMERGENCY ...      1         CNicholls  \n",
       "1       BENCH WARRANT ISSUED FROM 6TH DISTRICT COURT      1       DSchiavulli  \n",
       "2    WARRANT OF ARREST ON AFFIDAVIT - NOT RPT TO FBI      1           KMilian  \n",
       "3                             SIMPLE ASSAULT/BATTERY      1           ADaCruz  \n",
       "4                                 DISORDERLY CONDUCT      1         DMonteiro  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that limit defaults to 1000\n",
    "data_url='https://data.providenceri.gov/resource/rz3y-pz8v.json?%24limit=20000'\n",
    "response=requests.get(data_url)\n",
    "results = response.json()\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df['year'] = results_df['year'].astype(int)\n",
    "years = results_df['year'].unique()\n",
    "\n",
    "print(len(results_df), \"rows\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully geocoded records\n",
    "past_df = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_geocoded.csv'))\n",
    "past_df['year'] = past_df['year'].astype(int)\n",
    "\n",
    "# Records that could not be geocoded\n",
    "past_no_matches = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_non_geocoded.csv'))\n",
    "past_no_matches['year'] = past_no_matches['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-00065601</td>\n",
       "      <td>GREENE ST</td>\n",
       "      <td>2025-08-18T17:09:33.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>MKelley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00065576</td>\n",
       "      <td>1300 Block WEST MINISTER ST</td>\n",
       "      <td>2025-08-18T15:39:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00501413</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2025-08-18T11:54:49.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $11000 - ALL OTH LARCENY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2025-00065223</td>\n",
       "      <td>TINGLEY ST</td>\n",
       "      <td>2025-08-17T12:40:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT/BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-00501422</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>2025-08-17T03:07:44.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "13  2025-00065601                    GREENE ST  2025-08-18T17:09:33.000     8   \n",
       "19  2025-00065576  1300 Block WEST MINISTER ST  2025-08-18T15:39:00.000     8   \n",
       "21  2025-00501413                    FULTON ST  2025-08-18T11:54:49.000     8   \n",
       "51  2025-00065223                   TINGLEY ST  2025-08-17T12:40:00.000     8   \n",
       "60  2025-00501422                         OHIO  2025-08-17T03:07:44.000     8   \n",
       "\n",
       "    year            offense_desc statute_code  \\\n",
       "13  2025     Assault, Aggravated       11-5-2   \n",
       "19  2025  Request for Assistance     Not Used   \n",
       "21  2025          Larceny, Other      11-41-1   \n",
       "51  2025         Assault, Simple       11-5-3   \n",
       "60  2025               Vandalism      11-44-1   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "13  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1           MKelley   \n",
       "19                              No violations      0   Central Station   \n",
       "21         LARCENY/U $11000 - ALL OTH LARCENY      1     ADecristofano   \n",
       "51                     SIMPLE ASSAULT/BATTERY      1   Central Station   \n",
       "60     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ADecristofano   \n",
       "\n",
       "   unique_id violent_cat property_cat  \n",
       "13       NaN         NaN          NaN  \n",
       "19       NaN         NaN          NaN  \n",
       "21       NaN         NaN          NaN  \n",
       "51       NaN         NaN          NaN  \n",
       "60       NaN         NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    # concatenate past_df, results_df, and past_no_matches\n",
    "    df_all = pd.concat((past_df, results_df, past_no_matches))\n",
    "    # drop dupilcate records\n",
    "    df_all = df_all.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    results_df = df_all\n",
    "else:\n",
    "    df2 = results_df.copy()\n",
    "    # Identify new records by case number and time\n",
    "    df1 = past_df[['casenumber', 'reported_date']]\n",
    "\n",
    "    if exclude_past_no_match:\n",
    "        # Exclude past locations which returned no location matches\n",
    "        df1 = pd.concat((df1, past_no_matches[['casenumber', 'reported_date']]))\n",
    "    else:\n",
    "        # Add previously unmatched locations to the df to attempt geocoding again\n",
    "        df2 = pd.concat((df2, past_no_matches[past_no_matches['year'].isin(years)]))\n",
    "        df2 = df2.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    merged = df2.merge(df1, on=['casenumber', 'reported_date'], how='left', indicator=True)\n",
    "\n",
    "    # Identify new case records\n",
    "    new_records = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    # results_df is the DataFrame which will be geocoded\n",
    "    results_df = new_records\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load E911 data\n",
    "(needed to geocode block locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:\n",
      "Index(['SiteType', 'Site_GUID', 'Add_Full', 'AddNumFull', 'AddNum_Pre',\n",
      "       'Add_Number', 'AddNum_Suf', 'St_Full', 'St_PreMod', 'St_PreDir',\n",
      "       'St_PreTyp', 'St_Name', 'St_PosType', 'St_PosDir', 'St_PosMod',\n",
      "       'MSAGComm', 'ESN', 'State', 'Post_Code', 'Country', 'St_Alias1',\n",
      "       'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments',\n",
      "       'DateUpdate', 'geometry', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Add_Full</th>\n",
       "      <th>Add_Number</th>\n",
       "      <th>St_Full</th>\n",
       "      <th>St_Name</th>\n",
       "      <th>St_Alias1</th>\n",
       "      <th>St_Alias2</th>\n",
       "      <th>St_Alias3</th>\n",
       "      <th>St_Alias4</th>\n",
       "      <th>St_Alias5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>121 FARMINGTON AV</td>\n",
       "      <td>121.0</td>\n",
       "      <td>farmington av</td>\n",
       "      <td>farmington</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2 stry lght blu wht trm frnt prch blk rail</td>\n",
       "      <td>41.805353</td>\n",
       "      <td>-71.459654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>2 DEERFIELD TERR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>brwn shngles 2stry wht trim</td>\n",
       "      <td>41.785448</td>\n",
       "      <td>-71.420708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>3 DEERFIELD TERR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2stry wht split blk shttrs frnt prch</td>\n",
       "      <td>41.785195</td>\n",
       "      <td>-71.420797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37275</th>\n",
       "      <td>98 CYR ST</td>\n",
       "      <td>98.0</td>\n",
       "      <td>cyr st</td>\n",
       "      <td>cyr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tan brck 1stry wht trim brwn shttrs R grg, see VC</td>\n",
       "      <td>41.785209</td>\n",
       "      <td>-71.404274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37308</th>\n",
       "      <td>179 WHEELER AV</td>\n",
       "      <td>179.0</td>\n",
       "      <td>wheeler av</td>\n",
       "      <td>wheeler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>grey 3stry red brck base red canopies frnt hedges</td>\n",
       "      <td>41.781818</td>\n",
       "      <td>-71.403718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Add_Full  Add_Number         St_Full     St_Name St_Alias1  \\\n",
       "30282  121 FARMINGTON AV       121.0   farmington av  farmington      None   \n",
       "37261   2 DEERFIELD TERR         2.0  deerfield terr   deerfield      None   \n",
       "37262   3 DEERFIELD TERR         3.0  deerfield terr   deerfield      None   \n",
       "37275          98 CYR ST        98.0          cyr st         cyr      None   \n",
       "37308     179 WHEELER AV       179.0      wheeler av     wheeler      None   \n",
       "\n",
       "      St_Alias2 St_Alias3 St_Alias4 St_Alias5  \\\n",
       "30282      None      None      None      None   \n",
       "37261      None      None      None      None   \n",
       "37262      None      None      None      None   \n",
       "37275      None      None      None      None   \n",
       "37308      None      None      None      None   \n",
       "\n",
       "                                                Comments   Latitude  Longitude  \n",
       "30282         2 stry lght blu wht trm frnt prch blk rail  41.805353 -71.459654  \n",
       "37261                        brwn shngles 2stry wht trim  41.785448 -71.420708  \n",
       "37262               2stry wht split blk shttrs frnt prch  41.785195 -71.420797  \n",
       "37275  tan brck 1stry wht trim brwn shttrs R grg, see VC  41.785209 -71.404274  \n",
       "37308  grey 3stry red brck base red canopies frnt hedges  41.781818 -71.403718  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATH = os.path.join('.', 'inputs', 'e911', 'FACILITY_Sites_E911.shp')\n",
    "\n",
    "# gdf = GeoDataFrame of E911 sites\n",
    "gdf = gpd.read_file(FILEPATH)\n",
    "gdf['Latitude'] = gdf.geometry.y\n",
    "gdf['Longitude'] = gdf.geometry.x\n",
    "\n",
    "# Limit E911 sites to Providence\n",
    "gdf = gdf[gdf['MSAGComm'] == 'PROVIDENCE']\n",
    "\n",
    "# Standardize street names\n",
    "gdf['St_Full'] = gdf['St_Full'].str.lower().str.strip()\n",
    "gdf['St_Name'] = gdf['St_Name'].str.lower().str.strip()\n",
    "\n",
    "print(\"All columns:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "# View columns of interest\n",
    "to_view = ['Add_Full', 'Add_Number', 'St_Full', 'St_Name', 'St_Alias1', 'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments', 'Latitude', 'Longitude']\n",
    "gdf[to_view].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_address(address):\n",
    "    \"\"\"Categorizes locations by type and extracts necessary compononents for geocoding\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address : str\n",
    "        a singular value from the 'location' column of the case logs DataFrame\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple[int, list[str]]\n",
    "        1. an integer value indicating the address category\n",
    "              0 = Block\n",
    "              1 = Intersection\n",
    "              2 = Landmark\n",
    "        2. Address components needed to geocode the location\n",
    "              [block_number, street_name] for category 0\n",
    "              [street_name1, street_name2] for category 1\n",
    "              address (the input parameter) for category 2\n",
    "    \"\"\"\n",
    "    # Handles rare case where location == nan\n",
    "    if not isinstance(address, str):\n",
    "       return (None, [])\n",
    "\n",
    "    # Define block locations as having a number followed by 'Block', followed by any combination\n",
    "    # of alphanumeric characters and spaces\n",
    "    block_pattern = r'(\\d+)\\s+Block\\s+([\\dA-Za-z\\s\\']+)'\n",
    "\n",
    "    # Define intersection locations as having any combination of alphanumeric characters and spaces\n",
    "    # separated by 'AND', '&', or 'CORNER OF'\n",
    "    address = address.replace(' AND ', ' & ').replace('CORNER OF ', '')\n",
    "    intersection_pattern = r'([\\dA-Za-z\\s]+)\\s*&\\s*([\\dA-Za-z\\s]+)'\n",
    "\n",
    "    # Check if the address matches the block format\n",
    "    block_match = re.match(block_pattern, address)\n",
    "    if block_match:\n",
    "        block_number = block_match.group(1)\n",
    "        street_name = block_match.group(2).strip().lower()\n",
    "        return (0, (block_number, street_name))\n",
    "\n",
    "    # Check if the address matches the intersection format\n",
    "    intersection_match = re.match(intersection_pattern, address)\n",
    "    if intersection_match:\n",
    "        street_name1 = intersection_match.group(1).strip().lower()\n",
    "        street_name2 = intersection_match.group(2).strip().lower()\n",
    "        return (1, (street_name1, street_name2))\n",
    "\n",
    "    # If the address does not match either format, treat it as a landmark\n",
    "    return (2, address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_providence(latitude, longitude):\n",
    "    # Load the GeoDataFrame containing the polygon from the GeoPackage file\n",
    "    gdf_polygon = gpd.read_file(os.path.join('.', 'inputs', 'pvd_boundary.gpkg'), layer='pvd_boundary')\n",
    "    buffer_distance = 0.001\n",
    "    gdf_polygon = gdf_polygon['geometry'].iloc[0].buffer(buffer_distance)\n",
    "\n",
    "    # Create a Point geometry from the given latitude and longitude\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    # Check if the point is within the polygon\n",
    "    result = point.within(gdf_polygon)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert street names to E911 format\n",
    "number_to_words = {\n",
    "      '1st': 'first',\n",
    "      '2nd': 'second',\n",
    "      '3rd': 'third',\n",
    "      '4th': 'fourth',\n",
    "      '5th': 'fifth',\n",
    "      '6th': 'sixth',\n",
    "      '7th': 'seventh',\n",
    "      '8th': 'eighth',\n",
    "      '9th': 'ninth',\n",
    "      '10th': 'tenth',\n",
    "      '11th': 'eleventh',\n",
    "      '12th': 'twelfth',\n",
    "      '13th': 'thirteenth',\n",
    "      '14th': 'fourteenth',\n",
    "      '15th': 'fifteenth',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get block coordinates\n",
    "def get_block_coordinates(components, midpoint):\n",
    "    block, street = components\n",
    "    block = int(block)\n",
    "    stsuffix_to_abbr = {\n",
    "        'avenue': 'av',\n",
    "        'ave': 'av',\n",
    "        'street': 'st',\n",
    "        'terrace': 'terr',\n",
    "        'ter': 'terr',\n",
    "        'boulevard': 'blvd',\n",
    "        'drive': 'dr',\n",
    "        'road': 'rd',\n",
    "        'way': 'wy',\n",
    "        'lane': 'ln',\n",
    "        'court': 'ct',\n",
    "        'place': 'pl',\n",
    "        'parkway': 'pkwy',\n",
    "        'square': 'sq',\n",
    "        'walk': 'wk',\n",
    "        'plaza': 'plz',\n",
    "        'circle': 'cir'}\n",
    "\n",
    "    # Standardize street name to match E911 format\n",
    "    # Need to account for cases where streets are written slightly differently (ex. 'street' vs 'st', 'ave' vs 'av)\n",
    "    street = street.lower().strip()\n",
    "    # Remove periods from street names\n",
    "    street = street.replace('.', '')\n",
    "    street = street + ' '\n",
    "    # Reformat street suffixes\n",
    "    for k, v in stsuffix_to_abbr.items():\n",
    "        street = street.replace(f\" {k} \", f\" {v} \")\n",
    "    # Spell out numerical street names\n",
    "    for k, v in number_to_words.items():\n",
    "        street = street.replace(k, v)\n",
    "    # Remove trailing space\n",
    "    street = street.rstrip()\n",
    "\n",
    "    # Find E911 sites with matching street names / street name aliases\n",
    "    df = gdf[(gdf['St_Full'] == street) | (gdf['St_Alias1'] == street) | (gdf['St_Alias2'] == street) | (gdf['St_Alias3'] == street) | (gdf['St_Alias4'] == street) | (gdf['St_Alias5'] == street)]\n",
    "\n",
    "    # Try a more flexible strategy if no matches are returned\n",
    "    if len(df) == 0:\n",
    "        # Handle case where crime log location contains extra words/characters\n",
    "        def filter_fn(row):\n",
    "            if row['St_Full']:\n",
    "                # Remove apostrophes to minimize inconsistencies (e.g. \"o'connell\" vs \"oconnell\")\n",
    "                if row['St_Full'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                    return True\n",
    "            return False\n",
    "        df_temp = gdf[gdf.apply(filter_fn, axis=1)]\n",
    "        if len(df_temp) > 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            # Handle case where street suffix is missing\n",
    "            def filter_fn2(row):\n",
    "                if row['St_Name']:\n",
    "                    if row['St_Name'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                        return True\n",
    "                return False\n",
    "            df_temp = gdf[gdf.apply(filter_fn2, axis=1)]\n",
    "            df_temp = df_temp[(df_temp['Add_Number'] >= block) & (df_temp['Add_Number'] < block + 100) & (df_temp['Add_Number'] != 0)]\n",
    "            # Verify that there is only one street suffix for the given street name after filtering\n",
    "            if len(df_temp['St_PosType'].unique()) == 1:\n",
    "                df = df_temp\n",
    "        \n",
    "    # Filter E911 sites by block number\n",
    "    # Exclude E911 sites where 'Add_Number'==0; these correspond to E911 sites without address numbers\n",
    "    df = df[(df['Add_Number'] >= block) & (df['Add_Number'] < block + 100) & (df['Add_Number'] != 0)]\n",
    "    df = df.sort_values(by='Add_Number', ascending=True)\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Midpoint method\n",
    "        if midpoint:\n",
    "            latitude = (df['Latitude'].iloc[0] + df['Latitude'].iloc[-1])/2\n",
    "            longitude = (df['Longitude'].iloc[0] + df['Longitude'].iloc[-1])/2\n",
    "\n",
    "        # Middle house method\n",
    "        else:\n",
    "            if len(df) % 2 == 1:\n",
    "                middle_row = df.iloc[df.shape[0] // 2]\n",
    "                latitude = middle_row['Latitude']\n",
    "                longitude = middle_row['Longitude']\n",
    "            else:\n",
    "                middle_two_rows = df.iloc[df.shape[0] // 2 - 1 : df.shape[0] // 2 + 1]\n",
    "                latitude = middle_two_rows['Latitude'].mean()\n",
    "                longitude = middle_two_rows['Longitude'].mean()\n",
    "        return latitude, longitude\n",
    "    return 0, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert from RI State Plane system to WGS 84\n",
    "reproject = Transformer.from_crs(3438, 4326, always_xy=True)\n",
    "\n",
    "# Geocode intersections with RIDOT\n",
    "def get_intersection_coords(address):\n",
    "    base_url_ad='https://risegis.ri.gov/gpserver/rest/services/E911_StreetRange_Locator/GeocodeServer/findAddressCandidates?'\n",
    "    address=address.replace(' & ',' and ')\n",
    "    city='Providence'\n",
    "    try:\n",
    "        add_url=f'Street={address}&City={city}'\n",
    "        data_url = f'{base_url_ad}{add_url}&maxLocations=5&matchOutOfRange=true&WriteXYCoordFields=false&f=pjson'\n",
    "        response=requests.get(data_url)\n",
    "        add_data=response.json()['candidates'] # Collapse the dictionary by one level\n",
    "        if len(add_data)==0:\n",
    "            pass\n",
    "        elif len(add_data)==1:\n",
    "            longitude=add_data[0]['location']['x']\n",
    "            latitude=add_data[0]['location']['y'] \n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "        else:        \n",
    "            all_scores=[]\n",
    "            for m in add_data:\n",
    "                all_scores.append(m['score'])\n",
    "            maxs=max(all_scores) # Find highest score\n",
    "            maxs_idx=all_scores.index(maxs) # And its index (takes 1st highest value if several are equal)\n",
    "            # Get data for highest match and store\n",
    "            longitude=add_data[maxs_idx]['location']['x']\n",
    "            latitude=add_data[maxs_idx]['location']['y']\n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.82497, -71.41162)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load landmark coordinates\n",
    "df_landmark = pd.read_excel(os.path.join('.', 'inputs', 'landmarks.xlsx'))\n",
    "df_landmark['aliases'] = df_landmark['aliases'].astype(str).apply(lambda x: x.split(', '))\n",
    "df_landmark['aliases'] = df_landmark.apply(lambda x: x['aliases'] + [x['location']], axis=1)\n",
    "df_landmark['aliases'] = df_landmark['aliases'].apply(lambda x: [alias.lower() for alias in x])\n",
    "df_by_alias = df_landmark.explode('aliases', ignore_index=True)\n",
    "df_by_alias['aliases'] = df_by_alias['aliases'].drop_duplicates()\n",
    "\n",
    "def is_street(address):\n",
    "    address = address.lower().strip()\n",
    "    street_indicators = [' street', ' st',  ' st.', ' ave', ' av', ' avenue', ' blvd', ' rd', ' way', ' dr']\n",
    "    for indicator in street_indicators:\n",
    "        if address.endswith(indicator):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_landmark_coords(address):\n",
    "    if isinstance(address, float):\n",
    "        return 0, 0\n",
    "    try:\n",
    "        row = df_by_alias[df_by_alias['aliases'] == address.lower().strip()]\n",
    "        #lat = float(row['latitude'])\n",
    "        #long = float(row['longitude'])\n",
    "        lat = float(row.iloc[0]['latitude'])\n",
    "        long= float(row.iloc[0]['longitude'])\n",
    "        return lat, long\n",
    "    except:\n",
    "        if not is_street(address):\n",
    "            # Print the unrecognized landmark\n",
    "            print(address)\n",
    "        return 0, 0\n",
    "\n",
    "# Test\n",
    "get_landmark_coords('kennedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providence boundaries (with 0.005 degree buffer)\n",
    "min_lat = 41.7673\n",
    "max_lat = 41.8668\n",
    "min_long = -71.4774\n",
    "max_long = -71.3719\n",
    "\n",
    "##### Not needed -- in_providence() is used instead #####\n",
    "def within_bounds(latitude, longitude):\n",
    "        \"\"\"Returns True if the coordinates are within the Providence boundaries\"\"\"\n",
    "        if latitude > min_lat and latitude < max_lat and longitude > min_long and longitude < max_long:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, midpoint):\n",
    "    \"\"\"Returns a tuple of numerical (Latitude, Longitude) coordinates in WGS 84\n",
    "    Parameter:\n",
    "              address (string): the 'location' value from the case logs DataFrame\n",
    "              midpoint (boolean): indicates whether the midpoint method should be used in lieu of\n",
    "              the middle house method to calculate block centers\n",
    "              \"\"\"\n",
    "    # Get address category and necessary components for geocoding\n",
    "    category, components = categorize_address(address)\n",
    "\n",
    "    # Geocode block locations\n",
    "    if category == 0:\n",
    "        latitude, longitude = get_block_coordinates(components, midpoint)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'E911'\n",
    "\n",
    "    # Geocode intersection locations\n",
    "    elif category == 1:\n",
    "        latitude, longitude = get_intersection_coords(address)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'RIDOT'\n",
    "\n",
    "    # Geocode landmarks\n",
    "    else:\n",
    "      latitude, longitude = get_landmark_coords(address)\n",
    "      if in_providence(latitude, longitude):\n",
    "         return latitude, longitude, 'Landmark File'\n",
    "              \n",
    "    # Return None if no coordinates are found\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized landmarks (if any):\n"
     ]
    }
   ],
   "source": [
    "# THIS BLOCK DOES THE PROCESSING (will take time to execute)\n",
    "\n",
    "final_df = results_df.copy()\n",
    "# Set to False to use middle house method for calculating block centers\n",
    "use_midpoint = True\n",
    "\n",
    "print('Unrecognized landmarks (if any):')\n",
    "\n",
    "# Apply our geocoding function to add latitude and longitude columns\n",
    "final_df[['latitude', 'longitude', 'source']] = final_df['location'].apply(lambda x: pd.Series(get_coordinates(x, use_midpoint), dtype=object))\n",
    "# Store records that could not be geocoded\n",
    "no_matches_df = final_df[pd.isnull(final_df['latitude'])]\n",
    "\n",
    "# Store records that were successfully geocoded\n",
    "final_df = final_df[pd.notna(final_df['latitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the landmark file #\n",
    "Update 'landmarks.xlsx' with the appropriate coordinates. Coordinates can be found \n",
    "[here](https://www.openstreetmap.org/search?query=#map=12/41.8173/-71.4231)\n",
    "by searching a location name, right clicking on the map, and selecting \"Show address\".\n",
    "Invalid landmarks can be added to the spreadsheet with the coordinates (0, 0) to suppress future \n",
    "print statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records successfully geocoded\n",
      "333 records could not be geocoded\n"
     ]
    }
   ],
   "source": [
    "print(len(final_df), \"records successfully geocoded\")\n",
    "print(len(no_matches_df), \"records could not be geocoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3927169803.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df_copy = pd.concat((past_df, final_df), axis=0, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-00065601</td>\n",
       "      <td>GREENE ST</td>\n",
       "      <td>2025-08-18T17:09:33.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>MKelley</td>\n",
       "      <td>2025-00065601-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00065576</td>\n",
       "      <td>1300 Block WEST MINISTER ST</td>\n",
       "      <td>2025-08-18T15:39:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00065576-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00501413</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2025-08-18T11:54:49.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $11000 - ALL OTH LARCENY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>2025-00501413-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2025-00065223</td>\n",
       "      <td>TINGLEY ST</td>\n",
       "      <td>2025-08-17T12:40:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT/BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00065223-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-00501422</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>2025-08-17T03:07:44.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>2025-00501422-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "13  2025-00065601                    GREENE ST  2025-08-18T17:09:33.000     8   \n",
       "19  2025-00065576  1300 Block WEST MINISTER ST  2025-08-18T15:39:00.000     8   \n",
       "21  2025-00501413                    FULTON ST  2025-08-18T11:54:49.000     8   \n",
       "51  2025-00065223                   TINGLEY ST  2025-08-17T12:40:00.000     8   \n",
       "60  2025-00501422                         OHIO  2025-08-17T03:07:44.000     8   \n",
       "\n",
       "    year            offense_desc statute_code  \\\n",
       "13  2025     Assault, Aggravated       11-5-2   \n",
       "19  2025  Request for Assistance     Not Used   \n",
       "21  2025          Larceny, Other      11-41-1   \n",
       "51  2025         Assault, Simple       11-5-3   \n",
       "60  2025               Vandalism      11-44-1   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "13  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1           MKelley   \n",
       "19                              No violations      0   Central Station   \n",
       "21         LARCENY/U $11000 - ALL OTH LARCENY      1     ADecristofano   \n",
       "51                     SIMPLE ASSAULT/BATTERY      1   Central Station   \n",
       "60     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ADecristofano   \n",
       "\n",
       "            unique_id violent_cat property_cat latitude longitude source  \n",
       "13  2025-00065601-001         NaN          NaN     None      None   None  \n",
       "19  2025-00065576-001         NaN          NaN     None      None   None  \n",
       "21  2025-00501413-001         NaN          NaN     None      None   None  \n",
       "51  2025-00065223-001         NaN          NaN     None      None   None  \n",
       "60  2025-00501422-001         NaN          NaN     None      None   None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    final_df_copy = final_df\n",
    "# Concatenate past and present DFs\n",
    "else:\n",
    "    final_df_copy = pd.concat((past_df, final_df), axis=0, ignore_index=True)\n",
    "\n",
    "# Assign unique IDs to each offense\n",
    "casenum_counts = {casenum: 0 for casenum in final_df_copy['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    # Add 3 digits to each original case number\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "final_df_copy['unique_id'] = final_df_copy.apply(generate_unique_id, axis=1)\n",
    "\n",
    "# Do the same for unmatched locations\n",
    "if exclude_past_no_match and not geocode_all:\n",
    "    # Add new list to previous list of no matches\n",
    "    no_matches_df_new = pd.concat((past_no_matches, no_matches_df))\n",
    "else:\n",
    "    # If we tried to geocode the previous list of no matches, we don't need to add it again\n",
    "    # Concatenate with old list of no matches\n",
    "    no_matches_df_new = pd.concat((no_matches_df, past_no_matches[~past_no_matches['year'].isin(years)]))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "casenum_counts = {casenum: 0 for casenum in no_matches_df_new['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "no_matches_df_new['unique_id'] = no_matches_df_new.apply(generate_unique_id, axis=1)\n",
    "no_matches_df_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the crime categorization file\n",
    "If any unrecognized offense descriptions are printed out, open 'crime_cats.xlsx' and\n",
    "manually enter the new offense descriptions along with their appropriate crime\n",
    "categorizations. Then, rerun this cell and all following cells; \n",
    "no unrecognized offense descriptions should be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-00065601</td>\n",
       "      <td>GREENE ST</td>\n",
       "      <td>2025-08-18T17:09:33.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>MKelley</td>\n",
       "      <td>2025-00065601-001</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-00065576</td>\n",
       "      <td>1300 Block WEST MINISTER ST</td>\n",
       "      <td>2025-08-18T15:39:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No violations</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00065576-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-00501413</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2025-08-18T11:54:49.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Larceny, Other</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $11000 - ALL OTH LARCENY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>2025-00501413-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larceny-theft</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2025-00065223</td>\n",
       "      <td>TINGLEY ST</td>\n",
       "      <td>2025-08-17T12:40:00.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT/BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Station</td>\n",
       "      <td>2025-00065223-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-00501422</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>2025-08-17T03:07:44.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2025</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>11-44-1</td>\n",
       "      <td>VANDALISM/MALICIOUS INJURY TO PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>ADecristofano</td>\n",
       "      <td>2025-00501422-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casenumber                     location            reported_date month  \\\n",
       "13  2025-00065601                    GREENE ST  2025-08-18T17:09:33.000     8   \n",
       "19  2025-00065576  1300 Block WEST MINISTER ST  2025-08-18T15:39:00.000     8   \n",
       "21  2025-00501413                    FULTON ST  2025-08-18T11:54:49.000     8   \n",
       "51  2025-00065223                   TINGLEY ST  2025-08-17T12:40:00.000     8   \n",
       "60  2025-00501422                         OHIO  2025-08-17T03:07:44.000     8   \n",
       "\n",
       "    year            offense_desc statute_code  \\\n",
       "13  2025     Assault, Aggravated       11-5-2   \n",
       "19  2025  Request for Assistance     Not Used   \n",
       "21  2025          Larceny, Other      11-41-1   \n",
       "51  2025         Assault, Simple       11-5-3   \n",
       "60  2025               Vandalism      11-44-1   \n",
       "\n",
       "                                 statute_desc counts reporting_officer  \\\n",
       "13  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1           MKelley   \n",
       "19                              No violations      0   Central Station   \n",
       "21         LARCENY/U $11000 - ALL OTH LARCENY      1     ADecristofano   \n",
       "51                     SIMPLE ASSAULT/BATTERY      1   Central Station   \n",
       "60     VANDALISM/MALICIOUS INJURY TO PROPERTY      1     ADecristofano   \n",
       "\n",
       "            unique_id         violent_cat   property_cat latitude longitude  \\\n",
       "13  2025-00065601-001  Aggravated Assault            NaN     None      None   \n",
       "19  2025-00065576-001                 NaN            NaN     None      None   \n",
       "21  2025-00501413-001                 NaN  Larceny-theft     None      None   \n",
       "51  2025-00065223-001                 NaN            NaN     None      None   \n",
       "60  2025-00501422-001                 NaN            NaN     None      None   \n",
       "\n",
       "   source  \n",
       "13   None  \n",
       "19   None  \n",
       "21   None  \n",
       "51   None  \n",
       "60   None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('inputs' ,'crime_cats.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create dictionaries\n",
    "vc = dict(zip(df['offense_desc'], df['violent_cat']))\n",
    "pc = dict(zip(df['offense_desc'], df['property_cat']))\n",
    "\n",
    "def get_categories(offense_desc):\n",
    "    if offense_desc in vc:\n",
    "        return vc[offense_desc], pc[offense_desc]\n",
    "    else:\n",
    "        print('Unrecognized offense description:', offense_desc)\n",
    "        return None, None\n",
    "categorized = final_df_copy.copy()\n",
    "categorized[['violent_cat', 'property_cat']] = categorized['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "no_matches_df_new[['violent_cat', 'property_cat']] = no_matches_df_new['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "no_matches_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches_df_new = no_matches_df_new.drop(columns=['latitude', 'longitude', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:14: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_10112\\3151877746.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n"
     ]
    }
   ],
   "source": [
    "final_df = categorized\n",
    "final_df['year'] = final_df['year'].astype(int)\n",
    "no_matches_df_new['year'] = no_matches_df_new['year'].astype(int)\n",
    "\n",
    "reproject = Transformer.from_crs(4326, 3438, always_xy=True)\n",
    "\n",
    "overwrite_files = True\n",
    "if overwrite_files:\n",
    "    # Shapefile should be in RI State Plane system\n",
    "    long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "    shp_df = gpd.GeoDataFrame(final_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "\n",
    "    # Save the GeoDataFrame to a Shapefile\n",
    "    shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
    "\n",
    "    # Save separate Shapefiles by year\n",
    "    for year in final_df['year'].unique():\n",
    "        try: \n",
    "            # Make a new directory for the year if it doesn't already exist\n",
    "            os.mkdir(os.path.join(\"..\", \"outputs\", str(year)))\n",
    "        except:\n",
    "            pass\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "        shp_df = gpd.GeoDataFrame(year_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "        shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
    "\n",
    "    # Save the DataFrame to a CSV\n",
    "    #final_df = final_df.drop(columns=['geometry'])\n",
    "    final_df.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save the locations we have failed to geocode\n",
    "    no_matches_df_new.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_non_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save separate CSV files by year (excludes past years not included in the new data)\n",
    "    for year in years:\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.csv\"), index=False)\n",
    "        no_matches_year_df = no_matches_df_new[no_matches_df_new['year'] == year]\n",
    "        no_matches_year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_non_geocoded_{year}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
