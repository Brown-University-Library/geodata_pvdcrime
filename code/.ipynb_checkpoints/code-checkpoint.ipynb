{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, pandas as pd, geopandas as gpd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False while testing code, should be True for updates\n",
    "overwrite_files = True\n",
    "\n",
    "# Set to True to geocode all locations (including those that have already been geocoded) from scratch\n",
    "# Only used to ensure consistency of coordinate sources if geocoding method changes\n",
    "geocode_all = False # Should stay False for efficiency\n",
    "\n",
    "# Set to False to re-attempt geocoding for previously unmatched locations from the last 180 days\n",
    "exclude_past_no_match = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recent data (last 180 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8365 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-00011405</td>\n",
       "      <td>0 Block FERN ST</td>\n",
       "      <td>2024-02-14T08:59:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Stolen Vehicle\\Recovered</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>CHines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-00011402</td>\n",
       "      <td>100 Block JOHN ST</td>\n",
       "      <td>2024-02-14T08:48:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Stolen Vehicle\\Recovered</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>MHames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-00011380</td>\n",
       "      <td>200 Block WESTMINSTER ST</td>\n",
       "      <td>2024-02-14T03:49:24.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Suspicious Person</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>HViruet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-00011364</td>\n",
       "      <td>0 Block SPRUCE ST</td>\n",
       "      <td>2024-02-14T01:16:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2</td>\n",
       "      <td>FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>EPerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-00011353</td>\n",
       "      <td>0 Block FAIRVIEW ST</td>\n",
       "      <td>2024-02-14T00:02:59.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Assault, Aggravated</td>\n",
       "      <td>11-5-2.3</td>\n",
       "      <td>ASSAULT BY STRANGULATION 12-29-5</td>\n",
       "      <td>1</td>\n",
       "      <td>RSavage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      casenumber                  location            reported_date month  \\\n",
       "0  2024-00011405           0 Block FERN ST  2024-02-14T08:59:00.000     2   \n",
       "1  2024-00011402         100 Block JOHN ST  2024-02-14T08:48:00.000     2   \n",
       "2  2024-00011380  200 Block WESTMINSTER ST  2024-02-14T03:49:24.000     2   \n",
       "3  2024-00011364         0 Block SPRUCE ST  2024-02-14T01:16:00.000     2   \n",
       "4  2024-00011353       0 Block FAIRVIEW ST  2024-02-14T00:02:59.000     2   \n",
       "\n",
       "   year              offense_desc statute_code  \\\n",
       "0  2024  Stolen Vehicle\\Recovered     Not Used   \n",
       "1  2024  Stolen Vehicle\\Recovered     Not Used   \n",
       "2  2024         Suspicious Person     Not Used   \n",
       "3  2024       Assault, Aggravated       11-5-2   \n",
       "4  2024       Assault, Aggravated     11-5-2.3   \n",
       "\n",
       "                                statute_desc counts reporting_officer  \n",
       "0                              No Violations      0            CHines  \n",
       "1                              No Violations      0            MHames  \n",
       "2                              No Violations      0           HViruet  \n",
       "3  FELONY ASSAULT/ DANG. WEAPON OR SUBSTANCE      1            EPerry  \n",
       "4           ASSAULT BY STRANGULATION 12-29-5      1           RSavage  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that limit defaults to 1000\n",
    "data_url='https://data.providenceri.gov/resource/rz3y-pz8v.json?%24limit=20000'\n",
    "response=requests.get(data_url)\n",
    "results = response.json()\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df['year'] = results_df['year'].astype(int)\n",
    "years = results_df['year'].unique()\n",
    "\n",
    "print(len(results_df), \"rows\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully geocoded records\n",
    "past_df = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_geocoded.csv'))\n",
    "past_df['year'] = past_df['year'].astype(int)\n",
    "\n",
    "# Records that could not be geocoded\n",
    "past_no_matches = pd.read_csv(os.path.join('..', 'outputs', 'all', 'pvd_non_geocoded.csv'))\n",
    "past_no_matches['year'] = past_no_matches['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-00010730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-11T02:49:40.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>JMontilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47-8-A</td>\n",
       "      <td>LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47.1-3</td>\n",
       "      <td>Large capacity feeding devices prohibited</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2024-00010172</td>\n",
       "      <td>PINEHURST AVE</td>\n",
       "      <td>2024-02-09T11:02:09.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>JLanier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-00010132</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2024-02-09T06:19:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Larceny from Building</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM BLD</td>\n",
       "      <td>1</td>\n",
       "      <td>GScarcello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        casenumber                     location            reported_date  \\\n",
       "99   2024-00010730                          NaN  2024-02-11T02:49:40.000   \n",
       "143  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "144  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "172  2024-00010172                PINEHURST AVE  2024-02-09T11:02:09.000   \n",
       "180  2024-00010132  0 Block PLEASANT VALLEY PKY  2024-02-09T06:19:00.000   \n",
       "\n",
       "    month  year            offense_desc statute_code  \\\n",
       "99      2  2024  Request for Assistance     Not Used   \n",
       "143     2  2024                 Weapons    11-47-8-A   \n",
       "144     2  2024                 Weapons    11-47.1-3   \n",
       "172     2  2024         Assault, Simple       11-5-3   \n",
       "180     2  2024   Larceny from Building      11-41-1   \n",
       "\n",
       "                                       statute_desc counts reporting_officer  \\\n",
       "99                                    No Violations      0         JMontilla   \n",
       "143  LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL      1            LBoror   \n",
       "144       Large capacity feeding devices prohibited      1            LBoror   \n",
       "172                       SIMPLE ASSAULT OR BATTERY      1           JLanier   \n",
       "180                      LARCENY/U $1500 - FROM BLD      1        GScarcello   \n",
       "\n",
       "    unique_id violent_cat property_cat  \n",
       "99        NaN         NaN          NaN  \n",
       "143       NaN         NaN          NaN  \n",
       "144       NaN         NaN          NaN  \n",
       "172       NaN         NaN          NaN  \n",
       "180       NaN         NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    # concatenate past_df, results_df, and past_no_matches\n",
    "    df_all = pd.concat((past_df, results_df, past_no_matches))\n",
    "    # drop dupilcate records\n",
    "    df_all = df_all.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    results_df = df_all\n",
    "else:\n",
    "    df2 = results_df.copy()\n",
    "    # Identify new records by case number and time\n",
    "    df1 = past_df[['casenumber', 'reported_date']]\n",
    "\n",
    "    if exclude_past_no_match:\n",
    "        # Exclude past locations which returned no location matches\n",
    "        df1 = pd.concat((df1, past_no_matches[['casenumber', 'reported_date']]))\n",
    "    else:\n",
    "        # Add previously unmatched locations to the df to attempt geocoding again\n",
    "        df2 = pd.concat((df2, past_no_matches[past_no_matches['year'].isin(years)]))\n",
    "        df2 = df2.drop_duplicates(subset=['casenumber', 'reported_date', 'offense_desc', 'statute_code', 'statute_desc'])\n",
    "    merged = df2.merge(df1, on=['casenumber', 'reported_date'], how='left', indicator=True)\n",
    "\n",
    "    # Identify new case records\n",
    "    new_records = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    # results_df is the DataFrame which will be geocoded\n",
    "    results_df = new_records\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load E911 data\n",
    "(needed to geocode block locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:\n",
      "Index(['OBJECTID', 'DateUpdate', 'Site_GUID', 'SiteType', 'Add_Full',\n",
      "       'AddNumFull', 'AddNum_Pre', 'Add_Number', 'AddNum_Suf', 'St_Full',\n",
      "       'St_PreMod', 'St_PreDir', 'St_PreTyp', 'St_Name', 'St_PosType',\n",
      "       'St_PosDir', 'St_PosMod', 'MSAGComm', 'ESN', 'State', 'Post_Code',\n",
      "       'Country', 'St_Alias1', 'St_Alias2', 'St_Alias3', 'St_Alias4',\n",
      "       'St_Alias5', 'Comments', 'geometry', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Add_Full</th>\n",
       "      <th>Add_Number</th>\n",
       "      <th>St_Full</th>\n",
       "      <th>St_Name</th>\n",
       "      <th>St_Alias1</th>\n",
       "      <th>St_Alias2</th>\n",
       "      <th>St_Alias3</th>\n",
       "      <th>St_Alias4</th>\n",
       "      <th>St_Alias5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31510</th>\n",
       "      <td>121 FARMINGTON AV</td>\n",
       "      <td>121.0</td>\n",
       "      <td>farmington av</td>\n",
       "      <td>farmington</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2 stry lght blu wht trm frnt prch blk rail</td>\n",
       "      <td>41.805352</td>\n",
       "      <td>-71.459654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31661</th>\n",
       "      <td>12 CROWN ST</td>\n",
       "      <td>12.0</td>\n",
       "      <td>crown st</td>\n",
       "      <td>crown</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>wht 3 decka cncrt stps blk rail blcny</td>\n",
       "      <td>41.805878</td>\n",
       "      <td>-71.454730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38637</th>\n",
       "      <td>2 DEERFIELD TERR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>brwn shngles 2stry wht trim</td>\n",
       "      <td>41.785447</td>\n",
       "      <td>-71.420707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38638</th>\n",
       "      <td>3 DEERFIELD TERR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>deerfield terr</td>\n",
       "      <td>deerfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2stry wht split blk shttrs frnt prch</td>\n",
       "      <td>41.785194</td>\n",
       "      <td>-71.420797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38652</th>\n",
       "      <td>98 CYR ST</td>\n",
       "      <td>98.0</td>\n",
       "      <td>cyr st</td>\n",
       "      <td>cyr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tan brck 1stry wht trim brwn shttrs R grg, see VC</td>\n",
       "      <td>41.785208</td>\n",
       "      <td>-71.404273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Add_Full  Add_Number         St_Full     St_Name St_Alias1  \\\n",
       "31510  121 FARMINGTON AV       121.0   farmington av  farmington      None   \n",
       "31661        12 CROWN ST        12.0        crown st       crown      None   \n",
       "38637   2 DEERFIELD TERR         2.0  deerfield terr   deerfield      None   \n",
       "38638   3 DEERFIELD TERR         3.0  deerfield terr   deerfield      None   \n",
       "38652          98 CYR ST        98.0          cyr st         cyr      None   \n",
       "\n",
       "      St_Alias2 St_Alias3 St_Alias4 St_Alias5  \\\n",
       "31510      None      None      None      None   \n",
       "31661      None      None      None      None   \n",
       "38637      None      None      None      None   \n",
       "38638      None      None      None      None   \n",
       "38652      None      None      None      None   \n",
       "\n",
       "                                                Comments   Latitude  Longitude  \n",
       "31510         2 stry lght blu wht trm frnt prch blk rail  41.805352 -71.459654  \n",
       "31661              wht 3 decka cncrt stps blk rail blcny  41.805878 -71.454730  \n",
       "38637                        brwn shngles 2stry wht trim  41.785447 -71.420707  \n",
       "38638               2stry wht split blk shttrs frnt prch  41.785194 -71.420797  \n",
       "38652  tan brck 1stry wht trim brwn shttrs R grg, see VC  41.785208 -71.404273  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATH = os.path.join('.', 'inputs', 'e911', 'FACILITY_Sites_E911.shp')\n",
    "\n",
    "# gdf = GeoDataFrame of E911 sites\n",
    "gdf = gpd.read_file(FILEPATH)\n",
    "gdf['Latitude'] = gdf.geometry.y\n",
    "gdf['Longitude'] = gdf.geometry.x\n",
    "\n",
    "# Limit E911 sites to Providence\n",
    "gdf = gdf[gdf['MSAGComm'] == 'PROVIDENCE']\n",
    "\n",
    "# Standardize street names\n",
    "gdf['St_Full'] = gdf['St_Full'].str.lower().str.strip()\n",
    "gdf['St_Name'] = gdf['St_Name'].str.lower().str.strip()\n",
    "\n",
    "print(\"All columns:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "# View columns of interest\n",
    "to_view = ['Add_Full', 'Add_Number', 'St_Full', 'St_Name', 'St_Alias1', 'St_Alias2', 'St_Alias3', 'St_Alias4', 'St_Alias5', 'Comments', 'Latitude', 'Longitude']\n",
    "gdf[to_view].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_address(address):\n",
    "    \"\"\"Categorizes locations by type and extracts necessary compononents for geocoding\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address : str\n",
    "        a singular value from the 'location' column of the case logs DataFrame\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple[int, list[str]]\n",
    "        1. an integer value indicating the address category\n",
    "              0 = Block\n",
    "              1 = Intersection\n",
    "              2 = Landmark\n",
    "        2. Address components needed to geocode the location\n",
    "              [block_number, street_name] for category 0\n",
    "              [street_name1, street_name2] for category 1\n",
    "              address (the input parameter) for category 2\n",
    "    \"\"\"\n",
    "    # Handles rare case where location == nan\n",
    "    if not isinstance(address, str):\n",
    "       return (None, [])\n",
    "\n",
    "    # Define block locations as having a number followed by 'Block', followed by any combination\n",
    "    # of alphanumeric characters and spaces\n",
    "    block_pattern = r'(\\d+)\\s+Block\\s+([\\dA-Za-z\\s\\']+)'\n",
    "\n",
    "    # Define intersection locations as having any combination of alphanumeric characters and spaces\n",
    "    # separated by 'AND', '&', or 'CORNER OF'\n",
    "    address = address.replace(' AND ', ' & ').replace('CORNER OF ', '')\n",
    "    intersection_pattern = r'([\\dA-Za-z\\s]+)\\s*&\\s*([\\dA-Za-z\\s]+)'\n",
    "\n",
    "    # Check if the address matches the block format\n",
    "    block_match = re.match(block_pattern, address)\n",
    "    if block_match:\n",
    "        block_number = block_match.group(1)\n",
    "        street_name = block_match.group(2).strip().lower()\n",
    "        return (0, (block_number, street_name))\n",
    "\n",
    "    # Check if the address matches the intersection format\n",
    "    intersection_match = re.match(intersection_pattern, address)\n",
    "    if intersection_match:\n",
    "        street_name1 = intersection_match.group(1).strip().lower()\n",
    "        street_name2 = intersection_match.group(2).strip().lower()\n",
    "        return (1, (street_name1, street_name2))\n",
    "\n",
    "    # If the address does not match either format, treat it as a landmark\n",
    "    return (2, address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_providence(latitude, longitude):\n",
    "    # Load the GeoDataFrame containing the polygon from the GeoPackage file\n",
    "    gdf_polygon = gpd.read_file(os.path.join('.', 'inputs', 'pvd_boundary.gpkg'), layer='pvd_boundary')\n",
    "    buffer_distance = 0.001\n",
    "    gdf_polygon = gdf_polygon['geometry'].iloc[0].buffer(buffer_distance)\n",
    "\n",
    "    # Create a Point geometry from the given latitude and longitude\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    # Check if the point is within the polygon\n",
    "    result = point.within(gdf_polygon)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert street names to E911 format\n",
    "number_to_words = {\n",
    "      '1st': 'first',\n",
    "      '2nd': 'second',\n",
    "      '3rd': 'third',\n",
    "      '4th': 'fourth',\n",
    "      '5th': 'fifth',\n",
    "      '6th': 'sixth',\n",
    "      '7th': 'seventh',\n",
    "      '8th': 'eighth',\n",
    "      '9th': 'ninth',\n",
    "      '10th': 'tenth',\n",
    "      '11th': 'eleventh',\n",
    "      '12th': 'twelfth',\n",
    "      '13th': 'thirteenth',\n",
    "      '14th': 'fourteenth',\n",
    "      '15th': 'fifteenth',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get block coordinates\n",
    "def get_block_coordinates(components, midpoint):\n",
    "    block, street = components\n",
    "    block = int(block)\n",
    "    stsuffix_to_abbr = {\n",
    "        'avenue': 'av',\n",
    "        'ave': 'av',\n",
    "        'street': 'st',\n",
    "        'terrace': 'terr',\n",
    "        'ter': 'terr',\n",
    "        'boulevard': 'blvd',\n",
    "        'drive': 'dr',\n",
    "        'road': 'rd',\n",
    "        'way': 'wy',\n",
    "        'lane': 'ln',\n",
    "        'court': 'ct',\n",
    "        'place': 'pl',\n",
    "        'parkway': 'pkwy',\n",
    "        'square': 'sq',\n",
    "        'walk': 'wk',\n",
    "        'plaza': 'plz',\n",
    "        'circle': 'cir'}\n",
    "\n",
    "    # Standardize street name to match E911 format\n",
    "    # Need to account for cases where streets are written slightly differently (ex. 'street' vs 'st', 'ave' vs 'av)\n",
    "    street = street.lower().strip()\n",
    "    # Remove periods from street names\n",
    "    street = street.replace('.', '')\n",
    "    street = street + ' '\n",
    "    # Reformat street suffixes\n",
    "    for k, v in stsuffix_to_abbr.items():\n",
    "        street = street.replace(f\" {k} \", f\" {v} \")\n",
    "    # Spell out numerical street names\n",
    "    for k, v in number_to_words.items():\n",
    "        street = street.replace(k, v)\n",
    "    # Remove trailing space\n",
    "    street = street.rstrip()\n",
    "\n",
    "    # Find E911 sites with matching street names / street name aliases\n",
    "    df = gdf[(gdf['St_Full'] == street) | (gdf['St_Alias1'] == street) | (gdf['St_Alias2'] == street) | (gdf['St_Alias3'] == street) | (gdf['St_Alias4'] == street) | (gdf['St_Alias5'] == street)]\n",
    "\n",
    "    # Try a more flexible strategy if no matches are returned\n",
    "    if len(df) == 0:\n",
    "        # Handle case where crime log location contains extra words/characters\n",
    "        def filter_fn(row):\n",
    "            if row['St_Full']:\n",
    "                # Remove apostrophes to minimize inconsistencies (e.g. \"o'connell\" vs \"oconnell\")\n",
    "                if row['St_Full'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                    return True\n",
    "            return False\n",
    "        df_temp = gdf[gdf.apply(filter_fn, axis=1)]\n",
    "        if len(df_temp) > 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            # Handle case where street suffix is missing\n",
    "            def filter_fn2(row):\n",
    "                if row['St_Name']:\n",
    "                    if row['St_Name'].replace('\\'', '') in street.replace('\\'', ''):\n",
    "                        return True\n",
    "                return False\n",
    "            df_temp = gdf[gdf.apply(filter_fn2, axis=1)]\n",
    "            df_temp = df_temp[(df_temp['Add_Number'] >= block) & (df_temp['Add_Number'] < block + 100) & (df_temp['Add_Number'] != 0)]\n",
    "            # Verify that there is only one street suffix for the given street name after filtering\n",
    "            if len(df_temp['St_PosType'].unique()) == 1:\n",
    "                df = df_temp\n",
    "        \n",
    "    # Filter E911 sites by block number\n",
    "    # Exclude E911 sites where 'Add_Number'==0; these correspond to E911 sites without address numbers\n",
    "    df = df[(df['Add_Number'] >= block) & (df['Add_Number'] < block + 100) & (df['Add_Number'] != 0)]\n",
    "    df = df.sort_values(by='Add_Number', ascending=True)\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Midpoint method\n",
    "        if midpoint:\n",
    "            latitude = (df['Latitude'].iloc[0] + df['Latitude'].iloc[-1])/2\n",
    "            longitude = (df['Longitude'].iloc[0] + df['Longitude'].iloc[-1])/2\n",
    "\n",
    "        # Middle house method\n",
    "        else:\n",
    "            if len(df) % 2 == 1:\n",
    "                middle_row = df.iloc[df.shape[0] // 2]\n",
    "                latitude = middle_row['Latitude']\n",
    "                longitude = middle_row['Longitude']\n",
    "            else:\n",
    "                middle_two_rows = df.iloc[df.shape[0] // 2 - 1 : df.shape[0] // 2 + 1]\n",
    "                latitude = middle_two_rows['Latitude'].mean()\n",
    "                longitude = middle_two_rows['Longitude'].mean()\n",
    "        return latitude, longitude\n",
    "    return 0, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert from RI State Plane system to WGS 84\n",
    "reproject = Transformer.from_crs(3438, 4326, always_xy=True)\n",
    "\n",
    "# Geocode intersections with RIDOT\n",
    "def get_intersection_coords(address):\n",
    "    base_url_ad='https://risegis.ri.gov/gpserver/rest/services/E911_StreetRange_Locator/GeocodeServer/findAddressCandidates?'\n",
    "    address=address.replace(' & ',' and ')\n",
    "    city='Providence'\n",
    "    try:\n",
    "        add_url=f'Street={address}&City={city}'\n",
    "        data_url = f'{base_url_ad}{add_url}&maxLocations=5&matchOutOfRange=true&WriteXYCoordFields=false&f=pjson'\n",
    "        response=requests.get(data_url)\n",
    "        add_data=response.json()['candidates'] # Collapse the dictionary by one level\n",
    "        if len(add_data)==0:\n",
    "            pass\n",
    "        elif len(add_data)==1:\n",
    "            longitude=add_data[0]['location']['x']\n",
    "            latitude=add_data[0]['location']['y'] \n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "        else:        \n",
    "            all_scores=[]\n",
    "            for m in add_data:\n",
    "                all_scores.append(m['score'])\n",
    "            maxs=max(all_scores) # Find highest score\n",
    "            maxs_idx=all_scores.index(maxs) # And its index (takes 1st highest value if several are equal)\n",
    "            # Get data for highest match and store\n",
    "            longitude=add_data[maxs_idx]['location']['x']\n",
    "            latitude=add_data[maxs_idx]['location']['y']\n",
    "            longitude, latitude = reproject.transform(longitude, latitude)\n",
    "            return latitude, longitude\n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.82497, -71.41162)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load landmark coordinates\n",
    "df_landmark = pd.read_excel(os.path.join('.', 'inputs', 'landmarks.xlsx'))\n",
    "df_landmark['aliases'] = df_landmark['aliases'].astype(str).apply(lambda x: x.split(', '))\n",
    "df_landmark['aliases'] = df_landmark.apply(lambda x: x['aliases'] + [x['location']], axis=1)\n",
    "df_landmark['aliases'] = df_landmark['aliases'].apply(lambda x: [alias.lower() for alias in x])\n",
    "df_by_alias = df_landmark.explode('aliases', ignore_index=True)\n",
    "df_by_alias['aliases'] = df_by_alias['aliases'].drop_duplicates()\n",
    "\n",
    "def is_street(address):\n",
    "    address = address.lower().strip()\n",
    "    street_indicators = [' street', ' st',  ' st.', ' ave', ' av', ' avenue', ' blvd', ' rd', ' way', ' dr']\n",
    "    for indicator in street_indicators:\n",
    "        if address.endswith(indicator):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_landmark_coords(address):\n",
    "    if isinstance(address, float):\n",
    "        return 0, 0\n",
    "    try:\n",
    "        row = df_by_alias[df_by_alias['aliases'] == address.lower().strip()]\n",
    "        lat = float(row['latitude'])\n",
    "        long = float(row['longitude'])\n",
    "        return lat, long\n",
    "    except:\n",
    "        if not is_street(address):\n",
    "            # Print the unrecognized landmark\n",
    "            print(address)\n",
    "        return 0, 0\n",
    "\n",
    "# Test\n",
    "get_landmark_coords('kennedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providence boundaries (with 0.005 degree buffer)\n",
    "min_lat = 41.7673\n",
    "max_lat = 41.8668\n",
    "min_long = -71.4774\n",
    "max_long = -71.3719\n",
    "\n",
    "##### Not needed -- in_providence() is used instead #####\n",
    "def within_bounds(latitude, longitude):\n",
    "        \"\"\"Returns True if the coordinates are within the Providence boundaries\"\"\"\n",
    "        if latitude > min_lat and latitude < max_lat and longitude > min_long and longitude < max_long:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, midpoint):\n",
    "    \"\"\"Returns a tuple of numerical (Latitude, Longitude) coordinates in WGS 84\n",
    "    Parameter:\n",
    "              address (string): the 'location' value from the case logs DataFrame\n",
    "              midpoint (boolean): indicates whether the midpoint method should be used in lieu of\n",
    "              the middle house method to calculate block centers\n",
    "              \"\"\"\n",
    "    # Get address category and necessary components for geocoding\n",
    "    category, components = categorize_address(address)\n",
    "\n",
    "    # Geocode block locations\n",
    "    if category == 0:\n",
    "        latitude, longitude = get_block_coordinates(components, midpoint)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'E911'\n",
    "\n",
    "    # Geocode intersection locations\n",
    "    elif category == 1:\n",
    "        latitude, longitude = get_intersection_coords(address)\n",
    "        if in_providence(latitude, longitude):\n",
    "            return latitude, longitude, 'RIDOT'\n",
    "\n",
    "    # Geocode landmarks\n",
    "    else:\n",
    "      latitude, longitude = get_landmark_coords(address)\n",
    "      if in_providence(latitude, longitude):\n",
    "         return latitude, longitude, 'Landmark File'\n",
    "              \n",
    "    # Return None if no coordinates are found\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized landmarks (if any):\n"
     ]
    }
   ],
   "source": [
    "# THIS BLOCK DOES THE PROCESSING (will take time to execute)\n",
    "\n",
    "final_df = results_df.copy()\n",
    "# Set to False to use middle house method for calculating block centers\n",
    "use_midpoint = True\n",
    "\n",
    "print('Unrecognized landmarks (if any):')\n",
    "\n",
    "# Apply our geocoding function to add latitude and longitude columns\n",
    "final_df[['latitude', 'longitude', 'source']] = final_df['location'].apply(lambda x: pd.Series(get_coordinates(x, use_midpoint), dtype=object))\n",
    "# Store records that could not be geocoded\n",
    "no_matches_df = final_df[pd.isnull(final_df['latitude'])]\n",
    "\n",
    "# Store records that were successfully geocoded\n",
    "final_df = final_df[pd.notna(final_df['latitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the landmark file #\n",
    "Update 'landmarks.xlsx' with the appropriate coordinates. Coordinates can be found \n",
    "[here](https://www.openstreetmap.org/search?query=#map=12/41.8173/-71.4231)\n",
    "by searching a location name, right clicking on the map, and selecting \"Show address\".\n",
    "Invalid landmarks can be added to the spreadsheet with the coordinates (0, 0) to suppress future \n",
    "print statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 records successfully geocoded\n",
      "495 records could not be geocoded\n"
     ]
    }
   ],
   "source": [
    "print(len(final_df), \"records successfully geocoded\")\n",
    "print(len(no_matches_df), \"records could not be geocoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-00010730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-11T02:49:40.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>JMontilla</td>\n",
       "      <td>2024-00010730-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47-8-A</td>\n",
       "      <td>LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>2024-00010405-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47.1-3</td>\n",
       "      <td>Large capacity feeding devices prohibited</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>2024-00010405-002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2024-00010172</td>\n",
       "      <td>PINEHURST AVE</td>\n",
       "      <td>2024-02-09T11:02:09.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>JLanier</td>\n",
       "      <td>2024-00010172-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-00010132</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2024-02-09T06:19:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Larceny from Building</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM BLD</td>\n",
       "      <td>1</td>\n",
       "      <td>GScarcello</td>\n",
       "      <td>2024-00010132-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        casenumber                     location            reported_date  \\\n",
       "99   2024-00010730                          NaN  2024-02-11T02:49:40.000   \n",
       "143  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "144  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "172  2024-00010172                PINEHURST AVE  2024-02-09T11:02:09.000   \n",
       "180  2024-00010132  0 Block PLEASANT VALLEY PKY  2024-02-09T06:19:00.000   \n",
       "\n",
       "    month  year            offense_desc statute_code  \\\n",
       "99      2  2024  Request for Assistance     Not Used   \n",
       "143     2  2024                 Weapons    11-47-8-A   \n",
       "144     2  2024                 Weapons    11-47.1-3   \n",
       "172     2  2024         Assault, Simple       11-5-3   \n",
       "180     2  2024   Larceny from Building      11-41-1   \n",
       "\n",
       "                                       statute_desc counts reporting_officer  \\\n",
       "99                                    No Violations      0         JMontilla   \n",
       "143  LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL      1            LBoror   \n",
       "144       Large capacity feeding devices prohibited      1            LBoror   \n",
       "172                       SIMPLE ASSAULT OR BATTERY      1           JLanier   \n",
       "180                      LARCENY/U $1500 - FROM BLD      1        GScarcello   \n",
       "\n",
       "             unique_id violent_cat property_cat  latitude  longitude source  \n",
       "99   2024-00010730-001         NaN          NaN       NaN        NaN   None  \n",
       "143  2024-00010405-001         NaN          NaN       NaN        NaN   None  \n",
       "144  2024-00010405-002         NaN          NaN       NaN        NaN   None  \n",
       "172  2024-00010172-001         NaN          NaN       NaN        NaN   None  \n",
       "180  2024-00010132-001         NaN          NaN       NaN        NaN   None  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if geocode_all:\n",
    "    final_df_copy = final_df\n",
    "# Concatenate past and present DFs\n",
    "else:\n",
    "    final_df_copy = pd.concat((past_df, final_df), axis=0, ignore_index=True)\n",
    "\n",
    "# Assign unique IDs to each offense\n",
    "casenum_counts = {casenum: 0 for casenum in final_df_copy['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    # Add 3 digits to each original case number\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "final_df_copy['unique_id'] = final_df_copy.apply(generate_unique_id, axis=1)\n",
    "\n",
    "# Do the same for unmatched locations\n",
    "if exclude_past_no_match and not geocode_all:\n",
    "    # Add new list to previous list of no matches\n",
    "    no_matches_df_new = pd.concat((past_no_matches, no_matches_df))\n",
    "else:\n",
    "    # If we tried to geocode the previous list of no matches, we don't need to add it again\n",
    "    # Concatenate with old list of no matches\n",
    "    no_matches_df_new = pd.concat((no_matches_df, past_no_matches[~past_no_matches['year'].isin(years)]))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "casenum_counts = {casenum: 0 for casenum in no_matches_df_new['casenumber']}\n",
    "\n",
    "def generate_unique_id(row):\n",
    "    casenum = row['casenumber']\n",
    "    casenum_counts[casenum] += 1\n",
    "    unique_id = casenum + '-' + str(casenum_counts[casenum]).zfill(3)\n",
    "    return unique_id\n",
    "no_matches_df_new['unique_id'] = no_matches_df_new.apply(generate_unique_id, axis=1)\n",
    "no_matches_df_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the crime categorization file\n",
    "If any unrecognized offense descriptions are printed out, open 'crime_cats.xlsx' and\n",
    "manually enter the new offense descriptions along with their appropriate crime\n",
    "categorizations. Then, rerun this cell and all following cells; \n",
    "no unrecognized offense descriptions should be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenumber</th>\n",
       "      <th>location</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>offense_desc</th>\n",
       "      <th>statute_code</th>\n",
       "      <th>statute_desc</th>\n",
       "      <th>counts</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>violent_cat</th>\n",
       "      <th>property_cat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-00010730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-11T02:49:40.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Request for Assistance</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>No Violations</td>\n",
       "      <td>0</td>\n",
       "      <td>JMontilla</td>\n",
       "      <td>2024-00010730-001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47-8-A</td>\n",
       "      <td>LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>2024-00010405-001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-00010405</td>\n",
       "      <td>HARTFORD AVE</td>\n",
       "      <td>2024-02-10T02:22:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Weapons</td>\n",
       "      <td>11-47.1-3</td>\n",
       "      <td>Large capacity feeding devices prohibited</td>\n",
       "      <td>1</td>\n",
       "      <td>LBoror</td>\n",
       "      <td>2024-00010405-002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2024-00010172</td>\n",
       "      <td>PINEHURST AVE</td>\n",
       "      <td>2024-02-09T11:02:09.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Assault, Simple</td>\n",
       "      <td>11-5-3</td>\n",
       "      <td>SIMPLE ASSAULT OR BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>JLanier</td>\n",
       "      <td>2024-00010172-001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-00010132</td>\n",
       "      <td>0 Block PLEASANT VALLEY PKY</td>\n",
       "      <td>2024-02-09T06:19:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>Larceny from Building</td>\n",
       "      <td>11-41-1</td>\n",
       "      <td>LARCENY/U $1500 - FROM BLD</td>\n",
       "      <td>1</td>\n",
       "      <td>GScarcello</td>\n",
       "      <td>2024-00010132-001</td>\n",
       "      <td>None</td>\n",
       "      <td>Larceny-theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        casenumber                     location            reported_date  \\\n",
       "99   2024-00010730                          NaN  2024-02-11T02:49:40.000   \n",
       "143  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "144  2024-00010405                 HARTFORD AVE  2024-02-10T02:22:00.000   \n",
       "172  2024-00010172                PINEHURST AVE  2024-02-09T11:02:09.000   \n",
       "180  2024-00010132  0 Block PLEASANT VALLEY PKY  2024-02-09T06:19:00.000   \n",
       "\n",
       "    month  year            offense_desc statute_code  \\\n",
       "99      2  2024  Request for Assistance     Not Used   \n",
       "143     2  2024                 Weapons    11-47-8-A   \n",
       "144     2  2024                 Weapons    11-47.1-3   \n",
       "172     2  2024         Assault, Simple       11-5-3   \n",
       "180     2  2024   Larceny from Building      11-41-1   \n",
       "\n",
       "                                       statute_desc counts reporting_officer  \\\n",
       "99                                    No Violations      0         JMontilla   \n",
       "143  LICENSE OR PERMIT REQUIRED FOR CARRYING PISTOL      1            LBoror   \n",
       "144       Large capacity feeding devices prohibited      1            LBoror   \n",
       "172                       SIMPLE ASSAULT OR BATTERY      1           JLanier   \n",
       "180                      LARCENY/U $1500 - FROM BLD      1        GScarcello   \n",
       "\n",
       "             unique_id violent_cat   property_cat  latitude  longitude source  \n",
       "99   2024-00010730-001        None           None       NaN        NaN   None  \n",
       "143  2024-00010405-001        None           None       NaN        NaN   None  \n",
       "144  2024-00010405-002        None           None       NaN        NaN   None  \n",
       "172  2024-00010172-001        None           None       NaN        NaN   None  \n",
       "180  2024-00010132-001        None  Larceny-theft       NaN        NaN   None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('inputs' ,'crime_cats.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create dictionaries\n",
    "vc = dict(zip(df['offense_desc'], df['violent_cat']))\n",
    "pc = dict(zip(df['offense_desc'], df['property_cat']))\n",
    "\n",
    "def get_categories(offense_desc):\n",
    "    if offense_desc in vc:\n",
    "        return vc[offense_desc], pc[offense_desc]\n",
    "    else:\n",
    "        print('Unrecognized offense description:', offense_desc)\n",
    "        return None, None\n",
    "categorized = final_df_copy.copy()\n",
    "categorized[['violent_cat', 'property_cat']] = categorized['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "\n",
    "# Do the same for no_matches_df_new\n",
    "no_matches_df_new[['violent_cat', 'property_cat']] = no_matches_df_new['offense_desc'].apply(lambda x: pd.Series(get_categories(x)))\n",
    "no_matches_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches_df_new = no_matches_df_new.drop(columns=['latitude', 'longitude', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_14532\\1455171637.py:14: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
      "C:\\Users\\fdonnell\\AppData\\Local\\Temp\\ipykernel_14532\\1455171637.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n"
     ]
    }
   ],
   "source": [
    "final_df = categorized\n",
    "final_df['year'] = final_df['year'].astype(int)\n",
    "no_matches_df_new['year'] = no_matches_df_new['year'].astype(int)\n",
    "\n",
    "reproject = Transformer.from_crs(4326, 3438, always_xy=True)\n",
    "\n",
    "overwrite_files = True\n",
    "if overwrite_files:\n",
    "    # Shapefile should be in RI State Plane system\n",
    "    long_3438, lat_3438 = final_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "    shp_df = gpd.GeoDataFrame(final_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "\n",
    "    # Save the GeoDataFrame to a Shapefile\n",
    "    shp_df.to_file(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.shp\"), index=False)\n",
    "\n",
    "    # Save separate Shapefiles by year\n",
    "    for year in final_df['year'].unique():\n",
    "        try: \n",
    "            # Make a new directory for the year if it doesn't already exist\n",
    "            os.mkdir(os.path.join(\"..\", \"outputs\", str(year)))\n",
    "        except:\n",
    "            pass\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        long_3438, lat_3438 = year_df[['latitude', 'longitude']].apply(lambda x: reproject.transform(x[1], x[0]), axis=1).apply(pd.Series).values.T\n",
    "        shp_df = gpd.GeoDataFrame(year_df, geometry=gpd.points_from_xy(long_3438, lat_3438), crs = 'EPSG:3438')\n",
    "        shp_df.to_file(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.shp\"), index=False)\n",
    "\n",
    "    # Save the DataFrame to a CSV\n",
    "    final_df = final_df.drop(columns=['geometry'])\n",
    "    final_df.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save the locations we have failed to geocode\n",
    "    no_matches_df_new.to_csv(os.path.join(\"..\", \"outputs\", \"all\", \"pvd_non_geocoded.csv\"), index=False)\n",
    "\n",
    "    # Save separate CSV files by year (excludes past years not included in the new data)\n",
    "    for year in years:\n",
    "        year_df = final_df[final_df['year'] == year]\n",
    "        year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_geocoded_{year}.csv\"), index=False)\n",
    "        no_matches_year_df = no_matches_df_new[no_matches_df_new['year'] == year]\n",
    "        no_matches_year_df.to_csv(os.path.join(\"..\", \"outputs\", str(year), f\"pvd_non_geocoded_{year}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
